<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<link rel="alternate"
      type="application/rss+xml"
      href="https://www.birkey.co/rss.xml"
      title="RSS feed for https://www.birkey.co/">
<title>BirkeyCo</title>
<link href="static/style.css" rel="stylesheet" type="text/css" />
	   <link rel="apple-touch-icon" sizes="180x180" href="static/apple-touch-icon.png">
	   <link rel="icon" type="image/png" sizes="32x32" href="static/favicon-32x32.png">
	   <link rel="icon" type="image/png" sizes="16x16" href="static/favicon-16x16.png">
	   <link rel="manifest" href="/site.webmanifest">
	   <link rel="mask-icon" href="static/safari-pinned-tab.svg" color="#5bbad5">
	   <link rel="alternate" type="application/rss+xml" title="RSS Feed for birkey.co" href="/rss.xml">
	   <meta name="author" content="Kasim Tuman">
	   <meta name="referrer" content="no-referrer">
	   <meta name="msapplication-TileColor" content="#da532c">
	   <meta name="theme-color" content="#ffffff">
	   <meta http-equiv="content-type" content="application/xhtml+xml; charset=UTF-8">
	   <meta name="viewport" content="initial-scale=1,width=device-width,minimum-scale=1">
	  </head>
<body>
<div id="preamble" class="status"><br><center>
       <div style="display: inline-block; vertical-align:middle;">
  <a href="https://www.birkey.co/index.html" style="text-decoration: none;"><b>BIRKEY CONSULTING</b><br>
  </a><hr/><div style="text-align: justify;display: inline-block; width: 100%;">
<a class="title" href="https://github.com/oneness">ABOUT</a> &nbsp;<a class="title" href="https://www.birkey.co/rss.xml">RSS</a> &nbsp;<a class="title" href="https://www.birkey.co/archive.html">ARCHIVE</a></div></div>
  </center><br><br>
  <div style="margin-bottom: 3ch;text-transform: none;"></div></div>
<div id="content">

<div class="post-date">28 Dec 2025</div><h1 class="post-title"><a href="https://www.birkey.co/2025-12-28-once-csv-parser-to-rule-them-all.html">Once csv parser to rule them all</a></h1>
<p>
One would think that parsing CSV files is pretty straightforward until
you get bitten by all kinds of CSV files exists in the wild. Many
years ago, I have written a small CSV reader with following
requirements in mind:
</p>
<ul class="org-ul">
<li>Should not depend on any other code other than Clojure</li>
<li>Should allow me to control how I tokenize and transform lines</li>
<li>Should allow me to have complete controll over delimiting charactor
or charactors, file encoding, amount of lines to read and error
handling</li>
</ul>

<p>
The result is <a href="https://github.com/oneness/csvx">csvx</a>. I update it to work across Clojure and ClojureScript both in
NodeJS and browser environment. The entire code is less than 200 lines
including comments and blank lines. If you find yourself in need of a
csv reader with above requirements, you are welcome to steal the
code. Enjoy!
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-clojure.html">Clojure</a> <a href="https://www.birkey.co/tag-clojurescript.html">ClojureScript</a> </div>
<div class="post-date">02 Aug 2025</div><h1 class="post-title"><a href="https://www.birkey.co/2025-08-02-hacker-news-ai-coding-experience-analysis.html">Hacker news AI coding experience analysis</a></h1>
<p>
I have been using and experimenting with AI coding tools heavily for
the last 3 months or so since joining <a href="https://www.legionhealth.com/">Legion Health</a> as a Founding
Engineer. I was somewhat skeptical and approached using AI with
suspicion since ChatGPT came out. I use Emacs as my workbench and
optimized my workflow around using it as a terminal multiplexer, which
naturally fits with Claude Code that I use as my main programming
assistant. Below is my simple setup that might benefit other fellow
minimalist Emacs users.
</p>
<div class="org-src-container">
<pre class="src src-elisp">(use-package eat :ensure t :config
  (setq eat-term-name "xterm-256color" eat-kill-buffer-on-exit t
        process-adaptive-read-buffering nil eat-term-scrollback-size 500000)
  (define-key eat-semi-char-mode-map [?\s-v] #'eat-yank)
  (define-key eat-semi-char-mode-map [?\C-c ?\C-r] #'k/eat-redisplay))
(defun k/eat-redisplay ()
"Fix eat flicker/flash and display funkiness"
(interactive)
(unless (derived-mode-p 'eat-mode)
  (error "Not in an eat-mode buffer"))
(when (and (boundp 'eat-mode) eat-mode (boundp 'eat-terminal) eat-terminal)
  (let* ((process (eat-term-parameter eat-terminal 'eat--process))
         (window (get-buffer-window (current-buffer))))
    (if (and process (process-live-p process) window)
        (eat--adjust-process-window-size process (list window)))))
(setq-local window-adjust-process-window-size-function
            'window-adjust-process-window-size-smallest)
(goto-char (point-min))
(redisplay)
(goto-char (point-max))
(redisplay)
(setq-local window-adjust-process-window-size-function 'ignore))
</pre>
</div>

<p>
I start an eat shell and run:
</p>
<div class="org-src-container">
<pre class="src src-bash">cd ~/repos/project-x &amp;&amp; claude
</pre>
</div>

<p>
This is a fast moving landscape and I find following few points are
extremely helpful in my workflow:
</p>
<ul class="org-ul">
<li>Spend few minutes to gather up and feed context related to what needs to be
done to Claude at the start of a session.</li>
<li>Always ask to show a plan and instruct Claude for guidance if there
multiple options for a solution.</li>
<li>Provide a skeleton such as directory structure, file names, function names
and signatures.</li>
<li>Provide use case and acceptance criteria testing instructions.</li>
</ul>

<p>
On top of that, you need to make sure Claude has access to tools that
enhances its ability to look up relevant information. To provide more
balanced overview of the AI coding experience, I used a great data
analysis tool for Hacker News called <a href="https://camelai.com/">CamelAI</a>. Below are the result
that more or less resonates with my personal experience.
</p>
<div id="outline-container-orgb608789" class="outline-2">
<h2 id="orgb608789">üèÜ Top Stories by Engagement</h2>
<div class="outline-text-2" id="text-orgb608789">
<ul class="org-ul">
<li>Claude 3.7 Sonnet and Claude Code (2,127 points) üü¢
<ul class="org-ul">
<li>Overwhelmingly positive reception for AI coding capabilities</li>
<li>Demonstrates Claude's dominance in the space</li>
</ul></li>
<li>Cursor IDE lockout policy problems (1,511 points) üî¥
<ul class="org-ul">
<li>Major backlash against policy changes causing user cancellations</li>
<li>Shows fragility of user trust in AI tools</li>
</ul></li>
<li>AlphaEvolve: Gemini coding agent (1,036 points) üöÄ
<ul class="org-ul">
<li>Google's advanced algorithm design agent</li>
<li>High interest in autonomous coding capabilities</li>
</ul></li>
<li>"Enough AI copilots, we need AI HUDs" (964 points) üéõÔ∏è
<ul class="org-ul">
<li>Forward-thinking discussion about UI evolution</li>
<li>Community wants more integrated experiences</li>
</ul></li>
<li>Void: Open-source Cursor alternative (948 points) üîì
<ul class="org-ul">
<li>Strong demand for open-source alternatives</li>
<li>Privacy and control concerns driving adoption</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org0600797" class="outline-2">
<h2 id="org0600797">üìä Key Trends &amp; Patterns</h2>
<div class="outline-text-2" id="text-org0600797">
<ul class="org-ul">
<li>üéØ Claude Dominance in AI Coding
<ul class="org-ul">
<li>Evidence: Claude 3.7 Sonnet (2,127 pts), consistent praise in experience stories</li>
<li>Insight: Anthropic's Claude has emerged as the clear leader for serious coding work, with developers consistently praising its code quality and reasoning capabilities over competitors</li>
</ul></li>
<li>‚ö° Tool Fragmentation &amp; User Frustration
<ul class="org-ul">
<li>Evidence: Cursor problems (1,511 pts), multiple "stopped using AI" stories (365, 109 pts)</li>
<li>Insight: Users are jumping between tools due to policy changes, reliability issues, and unmet expectations. No single tool has achieved universal satisfaction, leading to "tool fatigue"</li>
</ul></li>
<li>üîÑ The Productivity Paradox
<ul class="org-ul">
<li>Evidence: "Anyone struggling to get value out of coding LLMs?" (345 pts), productivity studies showing mixed results</li>
<li>Insight: Despite massive hype, many developers struggle to see concrete productivity gains. The "almost right" code problem creates hidden productivity taxes that offset benefits</li>
</ul></li>
<li>üß† Cognitive Dependency Concerns
<ul class="org-ul">
<li>Evidence: "After months of coding with LLMs, I'm going back to using my brain" (365 pts)</li>
<li>Insight: Growing concern about over-reliance on AI leading to skill atrophy and reduced problem-solving capabilities among developers</li>
</ul></li>
<li>üè¢ Enterprise vs Individual Experience Gap
<ul class="org-ul">
<li>Evidence: Microsoft 365 Copilot disaster (602 pts) vs individual success stories</li>
<li>Insight: Stark divide between enterprise rollout failures and individual developer successes. Enterprise context adds complexity that current tools struggle with</li>
</ul></li>
<li>üîì Open Source Alternative Movement
<ul class="org-ul">
<li>Evidence: Void alternative (948 pts), Tabby self-hosted (366 pts)</li>
<li>Insight: Strong demand for open-source, self-hosted alternatives driven by privacy concerns, cost considerations, and desire for control</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org1de48b7" class="outline-2">
<h2 id="org1de48b7">üéØ Engineer Experience Patterns</h2>
<div class="outline-text-2" id="text-org1de48b7">
<ul class="org-ul">
<li>üü¢ Positive Experiences
<ul class="org-ul">
<li>Who: Experienced developers using AI as an enhancement tool</li>
<li>Patterns: Claude-based tools getting consistent praise, terminal-based tools popular with power users</li>
<li>Benefits: Code generation, debugging assistance, learning new patterns</li>
<li>Key Success Factor: Using AI to amplify existing skills, not replace them</li>
</ul></li>
<li>üî¥ Negative Experiences
<ul class="org-ul">
<li>Who: Beginners over-relying on AI, enterprise users with complex requirements</li>
<li>Patterns: Policy changes causing churn, productivity promises not materializing, "almost right" code creating more work</li>
<li>Problems: Skill degradation, tool reliability issues, hidden productivity costs</li>
<li>Key Failure Factor: Expecting AI to replace fundamental programming knowledge</li>
</ul></li>
<li>üü° Mixed Experiences
<ul class="org-ul">
<li>Who: Pragmatic developers experimenting with different approaches</li>
<li>Patterns: Tools working well for specific use cases, steeper learning curve than expected, context-dependent effectiveness</li>
<li>Insight: Success heavily depends on matching use case, experience level, and realistic expectations</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org2b66112" class="outline-2">
<h2 id="org2b66112">üìà Temporal Evolution (2024-2025)</h2>
<div class="outline-text-2" id="text-org2b66112">
<ul class="org-ul">
<li>Early 2024: Initial hype phase - GitHub Copilot going free, new tool launches</li>
<li>Mid 2024: Reality check phase - limitations becoming apparent, user frustrations mounting</li>
<li>Late 2024: Maturation phase - Claude emerges as leader, tool fragmentation increases</li>
<li>Early 2025: Sophistication phase - Claude 3.7/Code dominance, better understanding of limitations</li>
<li>Mid 2025: Pragmatic phase - Focus on specific use cases, open-source alternatives, realistic expectations</li>
</ul>
</div>
</div>
<div id="outline-container-orgf688f98" class="outline-2">
<h2 id="orgf688f98">üéØ Critical Insights for Engineers</h2>
<div class="outline-text-2" id="text-orgf688f98">
<ul class="org-ul">
<li>üí™ Skill Foundation is Critical
<ul class="org-ul">
<li>AI tools amplify existing programming skills rather than replace them. Developers who understand fundamentals see the most benefit.</li>
</ul></li>
<li>üéØ Context Matters Enormously
<ul class="org-ul">
<li>Success depends heavily on use case, project complexity, and domain. There's no universal "AI coding works" or "doesn't work."</li>
</ul></li>
<li>üîß Tool Landscape is Rapidly Changing
<ul class="org-ul">
<li>Claude-based tools currently leading, but the landscape shifts quickly. Expect to try multiple approaches.</li>
</ul></li>
<li>‚ö†Ô∏è Cognitive Risks are Real
<ul class="org-ul">
<li>Over-reliance can lead to skill degradation. Many successful developers use AI selectively while maintaining core problem-solving abilities.</li>
</ul></li>
<li>üìä Productivity Benefits are Mixed
<ul class="org-ul">
<li>Benefits exist but are often not as dramatic as promised. The "almost right" problem creates hidden costs that offset gains.</li>
</ul></li>
<li>üè¢ Enterprise Success ‚â† Individual Success
<ul class="org-ul">
<li>Individual developer success doesn't guarantee organizational success. Enterprise complexity creates additional challenges.</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgd5d7cdc" class="outline-2">
<h2 id="orgd5d7cdc">üîÆ Future Outlook</h2>
<div class="outline-text-2" id="text-orgd5d7cdc">
<ul class="org-ul">
<li>üéØ Specialization: Tools becoming more domain-specific and context-aware</li>
<li>ü§ù Hybrid Workflows: Combination of AI assistance and traditional coding becoming the norm</li>
<li>üî¨ Better Metrics: More sophisticated ways to measure actual productivity impact</li>
<li>üéì Education Evolution: Teaching AI-assisted development as a core skill</li>
<li>üîì Democratization: More open-source and self-hosted options emerging</li>
<li>üéõÔ∏è UI Innovation: Moving beyond copilots to more integrated experiences (AI HUDs)</li>
</ul>
</div>
</div>
<div id="outline-container-org36da3cc" class="outline-2">
<h2 id="org36da3cc">üîç Specific Tool Performance</h2>
<div class="outline-text-2" id="text-org36da3cc">
<ul class="org-ul">
<li>ü•á Claude: Clear winner for code quality, reasoning, and complex tasks</li>
<li>ü•à Cursor: Popular but plagued by policy and reliability issues</li>
<li>ü•â GitHub Copilot: Solid mainstream choice, good accessibility for beginners</li>
<li>üîì Open Source (Void/Tabby): Rising alternatives for privacy/control-conscious developers</li>
<li>‚ö†Ô∏è Enterprise Tools: Microsoft 365 Copilot struggled badly in enterprise rollouts</li>
</ul>
</div>
</div>
<div id="outline-container-org287b962" class="outline-2">
<h2 id="org287b962">üí° Bottom Line</h2>
<div class="outline-text-2" id="text-org287b962">
<ul class="org-ul">
<li>The AI coding experience is highly polarized - it works exceptionally well for some developers in specific contexts, but fails to deliver promised productivity gains for many others. Success requires:
<ul class="org-ul">
<li>Matching the right tool to the right use case</li>
<li>Maintaining realistic expectations</li>
<li>Preserving core programming skills</li>
<li>Understanding tool limitations</li>
<li>Being prepared to adapt as the landscape evolves</li>
</ul></li>
</ul>
</div>
</div>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-ai.html">AI</a> </div>
<div class="post-date">25 May 2025</div><h1 class="post-title"><a href="https://www.birkey.co/2025-05-25-mcp-explained-with-code.html">MCP explained with code</a></h1>
<p>
So you are curios about how Model Context Protocol works as a
stand-alone client and server, and as a hub to provide context for LLM
models to do their magic? Then read on.
</p>

<p>
In this post, I am going to write about following few points:
</p>
<ul class="org-ul">
<li>Why MCP?</li>
<li>How does it work?</li>
<li>What makes it worth learning and excited about?</li>
</ul>

<p>
<b>Disclaimer:</b> This blog post is not about making a claim of its merit
 only without its trade offs, which is a blog post for another day and
 another time. So take everything you read here with a grain of salt.
</p>
<div id="outline-container-orge2a41fa" class="outline-2">
<h2 id="orge2a41fa">Why MCP?</h2>
<div class="outline-text-2" id="text-orge2a41fa">
<p>
LLMs needs context to narrow its pattern recognitions so it can
provide more contextual help for the domain you are engaging them
with. MCP provides a plug and play way to do just that. I am not going
to repeat the excellent documentation from its web site <a href="https://modelcontextprotocol.io/introduction">here</a> but I'd
like to drive the point a bit further expanding upon their USB-C
analogy. USB-C is a universal standard (interface to be exact) that every
device manufactures uses so their device can be plugged into a USB
port of a computer. Once a device (think of it as a MCP Server)
connects to USB-C port, it exchanges information with the host about
its capabilities using a USB-C subsystem of your PC (think of it as a
MCP client) so you can communicate with the device. MCP client/server
behaves just like that and we are ready to the next section to see the
actual code so you can run to convince yourself.
</p>
</div>
</div>
<div id="outline-container-org12f4eb8" class="outline-2">
<h2 id="org12f4eb8">How does it work?</h2>
<div class="outline-text-2" id="text-org12f4eb8">
<p>
To understand any concept, I usually take it apart to its smallest
logical units to see them in actions. Below are all you need to run a
stand-alone MCP client and server in TypeScript:
</p>

<div class="org-src-container">
<pre class="src src-TypeScript">// Core bits of Server here. See full code:
// https://github.com/oneness/ts-mcp-client-server/blob/main/src/server.ts
class MCPServer {
  ... // omitted boiler plate code
  private setupToolHandlers() {
    // Handle list_tools requests
    this.server.setRequestHandler(ListToolsRequestSchema, async (): Promise&lt;ListToolsResult&gt; =&gt; {
      return {
        tools: [
          {
            name: "say_hello",
            description: "Says hello to a person",
            inputSchema: {
              type: "object",
              properties: {
                name: {
                  type: "string",
                  description: "The name of the person to greet",
                },
              },
              required: ["name"],
            },
          } as Tool,
          {
            name: "get_time",
            description: "Gets the current time",
            inputSchema: {
              type: "object",
              properties: {},
            },
          } as Tool,
        ],
      };
    });

    // Handle call_tool requests
    this.server.setRequestHandler(CallToolRequestSchema, async (request): Promise&lt;CallToolResult&gt; =&gt; {
      const { name, arguments: args } = request.params;

      switch (name) {
        case "say_hello":
          const personName = args?.name || "World";
          return {
            content: [
              {
                type: "text",
                text: `Hello, ${personName}! This is a greeting from the MCP server.`,
              },
            ],
          };

        case "get_time":
          return {
            content: [
              {
                type: "text",
                text: `Current time: ${new Date().toISOString()}`,
              },
            ],
          };

        default:
          throw new Error(`Unknown tool: ${name}`);
      }
    });
  }
  ... // omitted
}

// Client
// https://github.com/oneness/ts-mcp-client-server/blob/main/src/client.ts
class MCPClient {
  ... // omitted
  async listTools() {
    try {
      const response = await this.client.listTools() as ListToolsResult;

      console.log("Available tools:");
      response.tools.forEach((tool) =&gt; {
        console.log(`- ${tool.name}: ${tool.description}`);
      });

      return response.tools;
    } catch (error) {
      console.error("Error listing tools:", error);
      return [];
    }
  }

  async callTool(name: string, args: any = {}) {
    try {
      const response = await this.client.callTool({
        name,
        arguments: args,
      }) as CallToolResult;

      console.log(`Tool '${name}' response:`);
      response.content.forEach((content) =&gt; {
        if (content.type === "text") {
          console.log(content.text);
        }
      });

      return response;
    } catch (error) {
      console.error(`Error calling tool '${name}':`, error);
    }
  }
 ... //omitted 
}
</pre>
</div>

<p>
As you have noticed, there are few interfaces (functions with args and
return schema ) that you need to implement so client and server can
speak to each other using Request/Response format that they
understand (JSON2.0 RPC if you are curious).
</p>

<p>
Now you understand how a stand-alone MCP client and server communicates
with each other (I highly recommend you clone the repo and run `npm
run mcp` to see it in action), Let us see the actual LLM chat that
uses MCP client to talk to LLM by providing MCP server capabilities as
a context to it. LLM can use the structured data (MCP capabilities)
to determine what MCP server tool it can use to answer user's request,
which in turn MCP client uses to execute the tool. Then the tool
response is provided back to LLM so it can formulate a final response
back to the user. Here is the simple ASCII diagram that visualizes the
flow I am talking about:
</p>

<div class="org-src-container">
<pre class="src src-text">+----------+      +------------+      +-----------------+      +-----+
|   User   |      | MCP Client |      | MCP Server Tool |      | LLM |
+----------+      +------------+      +-----------------+      +-----+
     |                 |                  |                  |
     |                 | 0. Connect &amp; Get |                  |
     |                 |    Capabilities  |                  |
     |                 +-----------------&gt;|                  |
     |                 |&lt;-----------------+                  |
     |                 | (Capabilities now known by Client)  |
     |                 |                  |                  |
     |                 | 1. Setup System  |                  |
     |                 |    Prompt w/ MCP |                  |
     |                 |    Capabilities  |                  |
     |                 +------------------------------------&gt;|
     |                 |                  |                  |
     |                 |                  | (LLM is now      |
     |                 |                  |  aware of tools) |
     |                 |                  |                  |
     |  2. Chat Req.   |                  |                  |
     +----------------&gt;|                  |                  |
     |                 |                  |                  |
     |                 | 3. User Query    |                  |
     |                 |  (subsequent)    |                  |
     |                 +------------------------------------&gt;|
     |                 |                  |                  |
     |                 |                  | 4. Process Query |
     |                 |                  |    &amp; Context     |
     |                 |                  |                  |
     |                 |                  |&lt;-----------------| (Tool identified?)
     |                 |                  | 5. Tool Exec.    |
     |                 |                  |    Request       |
     |                 |&lt;------------------------------------|
     |                 |                  |                  |
     |                 | 6. Execute Tool  |                  |
     |                 +-----------------&gt;|                  |
     |                 |                  |                  |
     |                 |&lt;-----------------+                  |
     |                 | 7. Tool Output   |                  |
     |                 |                  |                  |
     |                 | 8. Tool Output   |                  |
     |                 +------------------------------------&gt;|
     |                 |                  |                  |
     |                 |                  |                  |
     |                 |                  |                  |
     |                 |&lt;------------------------------------|
     |                 |                  | 9. Final Response|
     |&lt;----------------+                  |                  |
     | 10. Chat Resp.  |                  |                  |


</pre>
</div>

<p>
Here is the code that shows above flow in action:
</p>

<div class="org-src-container">
<pre class="src src-TypeScript">// Omitted for brevity. See below link for details
// https://github.com/oneness/ts-mcp-client-server/blob/main/src/llm.ts#L69
async processMessage(userMessage: string): Promise&lt;string&gt; {
  console.log(`\nü§ñ Processing: "${userMessage}"`);

  // Add user message to conversation
  this.conversationHistory.push({
    role: "user",
    content: userMessage
  });

  try {
    // Prepare tools for Claude
    const tools = this.convertMCPToolsToAnthropicFormat();

    // Get Claude's response
    const response = await this.anthropic.messages.create({
      model: "claude-3-5-sonnet-20241022",
      max_tokens: 1000,
      system: this.systemPrompt,
      messages: this.conversationHistory,
      tools: tools.length &gt; 0 ? tools : undefined,
    });

    console.log(`üß† Claude response:`, JSON.stringify(response, null, 2));

    // Process the response
    let finalResponse = "";
    const toolResults: MCPToolResult[] = [];

    // Handle different content types
    for (const content of response.content) {
      if (content.type === 'text') {
        finalResponse += content.text;
      } else if (content.type === 'tool_use') {
        console.log(`üîß Claude wants to use tool: ${content.name} with args:`, content.input);

        // Call the MCP tool
        const mcpResult = await this.mcpClient.callTool(content.name, content.input);

        let toolResultText = "No result";
        if (mcpResult &amp;&amp; mcpResult.content) {
          toolResultText = mcpResult.content
            .filter(c =&gt; c.type === 'text')
            .map(c =&gt; c.text)
            .join('\n');
        }

        toolResults.push({
          tool: content.name,
          result: toolResultText
        });

        // Add tool result to conversation for Claude's next response
        this.conversationHistory.push({
          role: "assistant",
          content: response.content
        });

        this.conversationHistory.push({
          role: "user",
          content: [
            {
              type: "tool_result",
              tool_use_id: content.id,
              content: toolResultText
            }
          ]
        });
      }
    }

    // If we used tools, get Claude's final response incorporating the results
    if (toolResults.length &gt; 0) {
      console.log(`üìä Tool results:`, toolResults);

      const finalCompletion = await this.anthropic.messages.create({
        model: "claude-3-5-sonnet-20241022",
        max_tokens: 1000,
        system: this.systemPrompt,
        messages: this.conversationHistory,
        tools: tools.length &gt; 0 ? tools : undefined,
      });

      // Extract text from final response
      finalResponse = "";
      for (const content of finalCompletion.content) {
        if (content.type === 'text') {
          finalResponse += content.text;
        }
      }

      this.conversationHistory.push({
        role: "assistant",
        content: finalCompletion.content
      });
    } else {
      // No tools were used, add the response to history
      this.conversationHistory.push({
        role: "assistant",
        content: response.content
      });
    }

    return finalResponse;

  } catch (error) {
    console.error('Error calling Claude:', error);
    return "I'm sorry, I encountered an error processing your request.";
  }
}
</pre>
</div>
</div>
</div>
<div id="outline-container-org0e026ce" class="outline-2">
<h2 id="org0e026ce">What makes it worth learning and excited about?</h2>
<div class="outline-text-2" id="text-org0e026ce">
<p>
If you have been following LLM landscape, you might have come to a
realization that most of us (unless you are an AI researcher) are in
the business of providing the most accurate and up to date context to
the foundational LLM models. MCP unifies the way LLM models, Consumer
Applications (clients) and Resource Providers (servers) communicates
thus reducing M*N integration issues to M+N, which is worth learning,
implementing and being excited about. Even without the context of LLM,
I hope more data or service providers exposes their system
capabilities by implementing MCP server contracts. That would
dramatically reduce so much wasted time spent on ad-hoc integration
API glue code.
</p>

<p>
Hope you learned a thing or two about MCP. Keep learning and have fun!
</p>
</div>
</div>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-mcp.html">mcp</a> </div>
<div class="post-date">15 Apr 2025</div><h1 class="post-title"><a href="https://www.birkey.co/2025-04-15-nix:-better-way-for-fun-and-profit.html">Nix: Better way for fun and profit</a></h1>
<p>
Nix is started in 2003 as a research project aimed to solve the
problem of <b>reliable software deployment</b>. The PhD thesis titled <b>The
Purely Functional Software Deployment Model</b> proposed a novel way of
building software where the final artifact is purely dependent on the
inputs to the build system, which is a pure function in a mathematical
sense. Regardless of where you are in your nix journey, I can't
recommend this paper (<a href="https://edolstra.github.io/pubs/phd-thesis.pdf">thesis</a>) enough. It is very approachable and
worth a read so you learn from first principle of what, why and how
about Nix.
</p>

<p>
Nix is a software build and management system that can replace
traditional package managers, build environments and configuration
tools. Due to the inherent complexity of the problem domain nix is
designed to solve and its long history, it has pretty steep learning
curve but not unsurmountable. One of the common point of confusions is
how the term `Nix` is used in documentations, tutorials and
blogosphere. So let me clarify few terminologies that often gets
overloaded. 
</p>

<ul class="org-ul">
<li><b>Nix:</b> Unless otherwise fully qualified, I use it to mean the
software build and management system.</li>
<li><b>Nix CLI:</b> The nix command line client that one uses to interact with nix.</li>
<li><b>Nix DSL:</b> The domain specific language that nix uses to generate a
software package. I would like to see everyone start using it to
mean the nix language.</li>
<li><b>Flakes:</b> A Nix DSL with number of conventions that is designed to
ease the configuration and discoverability of software packaging lifecycle.</li>
<li><b>NixOS:</b> The final artifact, which is happened to be a Linux
Operating System that is generated by feeding Nix DSL to nix. I will
not be covering it in this blog post.</li>
</ul>

<p>
After few false starts and restarts, below are what I believe to be
better ways for getting started, using nix for fun and profit.
</p>
<div id="outline-container-org2f32676" class="outline-2">
<h2 id="org2f32676">Installation</h2>
<div class="outline-text-2" id="text-org2f32676">
<p>
I have a following bash script to install a specific version so I can
have control over which version to install, what features enable and
disable.
</p>

<div class="org-src-container">
<pre class="src src-bash">#!/usr/bin/env bash
set -Eeuo pipefail

VERSION='2.28.1' # replace it with the latest version
URL="https://releases.nixos.org/nix/nix-${VERSION}/install"
MY_CONF="$HOME/.dotfiles/nix/nix.conf"
sh &lt;(curl --location "${URL}") \
     --daemon \
     --no-channel-add \
     --nix-extra-conf-file ${MY_CONF}
# conf file has this content
experimental-features = nix-command flakes
</pre>
</div>
<p>
The `&#x2013;no-channel-add` and the extra conf file needs some
explanation. Nix called a remote url a channel that gets automatically
installed, where nix uses to retrieve package definitions (Nix DSL) to
manage packages. It introduces a state, which is currently installed
channel url that is outside of Nix DSL, thus defeating the purpose of
reproducibility. It is considered legacy feature and not needed by
flakes, an experimental feature already widely adopted by the
community. So I highly recommend enabling flakes and additional
commands to interact with it.
</p>
</div>
</div>
<div id="outline-container-org2b5adb4" class="outline-2">
<h2 id="org2b5adb4">Using for fun and sanity</h2>
<div class="outline-text-2" id="text-org2b5adb4">
<p>
Every project depends on existing software that is beyond your
control. Nix DSL enables you to declaratively specify your projects
dependencies, a repo or a tar-ball down to the file digest of its
content, which is what gives nix superpowers of being a deterministic
and reproducible package manager. This means that if your inputs stays
the same, nix guarantees that it produces the exact same output
regardless of when and where. Below is a flake that pulls in latest
version of Clojure into your project.
</p>

<div class="org-src-container">
<pre class="src src-nix">{
  # optional attribute
  description = "My awesome Clojure/ClojureScript project";

  # required attribute
  inputs = {
    # nix dsl fns useful for writing flakes
    flake-utils.url = "github:numtide/flake-utils/v1.0.0";
    # Pins state of the packages to a specific commit sha
    pinnedPkgs.url = "github:NixOS/nixpkgs/c46290747b2aaf090f48a478270feb858837bf11";
  };

  # required attribute
  outputs = { self, flake-utils, pinnedPkgs }@inputs :
  flake-utils.lib.eachDefaultSystem (system:
  let pinnedSysPkgs = inputs.pinnedPkgs.legacyPackages.${system};
  in
  {
    devShells.default = pinnedSysPkgs.mkShell {
      packages = [
        pinnedSysPkgs.clojure
      ];

      # commands to run in the development interactive shell
      shellHook = ''
        echo To get Clojure REPL, Run:
        echo clojure
        echo To get ClojureScript REPL, Run:
        echo clj -Sdeps \'{:deps {org.clojure/clojurescript {:mvn/version "1.11.132"}}}\' -M -m cljs.main --repl
      '';
    };
    packages = {
      docker = pinnedSysPkgs.dockerTools.buildLayeredImage {
        name = "My awesome Clj docker image built by nix";
        tag = "latest";
        contents = [pinnedSysPkgs.clojure];
      };
    };
  });
}

</pre>
</div>

<p>
Do not worry too much about not understanding above nix dsl code. The
most important thing to know is that it is nix dsl referred to as a
flake that specifies its inputs and outputs declaratively. Save above
code as `flake.nix`, which is a convention, then run `nix develop` to
get an interactive shell with Clojure in your path. Nix can do way
more than this. However, I recommend you just start with solving
project dependencies problem. Above flake gives you following
benefits:
</p>
<ul class="org-ul">
<li>Ability to pin the exact versions of your project dependencies.</li>
<li>Cross platform development environment that works
both in MacOS and various flavors of Linux.</li>
<li>Determinate and reproducible development environment that
eliminates "it works on my machine" tooling issues.</li>
</ul>
<p>
One important thing to notice here is the way I chose to reference
the url inputs of the flake. I deliberately used tags or commit sha to
prevent the state of the urls (thus the state of the nix DSL) change
under me, which defeats the purpose of having a determinate
and reproducible way to get a development environment. I have
following bash script that prints available tags and corresponding
commit hash:
</p>
<div class="org-src-container">
<pre class="src src-bash"> git_tag_sha () {
   repo="$1"
   echo "********************************************************"
   echo "Available release and commit sha for pinning are:"
   echo "********************************************************"
   printf "\033[1m%-12s %s\033[0m\n" "release" "commit sha"
   curl -s https://github.com/$repo/tags | grep -oP 'href="\K[^"]*(releases/tag|nixpkgs/commit)[^"]*' | awk -F '/' 'NR%2{tag=$NF; next} {printf "%-12s %s\n", tag, $NF}'
   echo
   echo "****************************************************************************"
   echo "Please replace the commit sha of following line to pin pkgs to a commit sha: "
   echo "pinnedPkgs.url = github:$repo/&lt;commit&gt;"
   echo "****************************************************************************"
   echo
}
# You can run it like this:
 git_tag_sha "NixOS/nixpkgs"
</pre>
</div>
</div>
</div>
<div id="outline-container-orgec3469a" class="outline-2">
<h2 id="orgec3469a">Profiting in CI/CD and production</h2>
<div class="outline-text-2" id="text-orgec3469a">
<p>
This is probably one of the most frictionless and rewarding outcome of
using nix. Nix is designed to solve the problem of software deployment
after all but the wholesale adoption in production might prove to be
too much for the final gain. To spare yourself countless hours of
frustration, I highly recommend you start with using it to build
docker image if you happened to use docker and Kubernetes. Nix has
superb built-in support for making the smallest possible docker image
otherwise impossible. Above flake already includes `docker` image as
one of its packages output. Here is how you build and load the docker image:
</p>

<div class="org-src-container">
<pre class="src src-bash">nix build .#docker # the image will be in ./result
docker load &lt; ./result # to get it ready to be deployed
</pre>
</div>

<p>
It is a declarative way (using the power of Nix DSL compared to using
series commands in YAML file) to deterministically reproduce layered
Docker image that saves time and money in your DevOps journey. Have
fun and enjoy!
</p>
</div>
</div>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-nix.html">nix</a> </div>
<div class="post-date">18 Jun 2023</div><h1 class="post-title"><a href="https://www.birkey.co/2023-06-18-google-bard-and-emacs.html">Google Bard and Emacs</a></h1>
<p>
After reading a Google blog post on Bard's increasing ability for
reasoning about source code, I thought I would give it a try. The
issue is that not like OpenAI, Bard currently does not have an http
API that I can use via curl. I googled around and came across the
`bard-rs` project here: <a href="https://github.com/Alfex4936/Bard-rs">https://github.com/Alfex4936/Bard-rs</a>. So I
followed the excellent instruction to get set up using bard from
command line and its is pretty solid. I used following Elisp to use
`bard-rs` from Emacs' compilation buffer here:
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(defun kcompilation-start (cmd name &amp;optional mode)
  (let* ((compile-command nil)
         (compilation-save-buffers-predicate 'ignore)
         (compilation-buffer
          (compilation-start cmd
                             (if (equal mode 'read-only) nil t)
                             (lambda (m)
                               (or (when (boundp 'name)
                                     (format "*%s*" name))
                                   (buffer-name))))))
    (when current-prefix-arg
      (with-current-buffer compilation-buffer
        (switch-to-prev-buffer (get-buffer-window (current-buffer)))))
    (message (format "Running %s in %s ..." cmd name))))

(defun kprompt-bard (&amp;optional p)
  "Prompts for input to send it to `bard` using `bard-rs` in
*bard-prompt* buffer. If mark-active, uses the text in the region
 as the prompt"
  (interactive "P")
  (let* ((bs "bard-prompt")
         (bname (format "*%s*" bs))
         (bname (if (get-buffer bname)
                    bname
                  (progn (kcompilation-start "bard-rs -e ~/.env" bs)
                         bname)))
         (prompt (if mark-active
                     (replace-regexp-in-string
                      "\n"
                      ""
                      (buffer-substring-no-properties (region-beginning) (region-end)))
                   (read-string "AI Chat Prompt: "))))
    (with-current-buffer (pop-to-buffer bname)
      (when p
        (end-of-buffer)
        (insert "!reset")
        (comint-send-input)
        (end-of-buffer)
        (insert prompt)
        (comint-send-input))
      (when (not p)
        (end-of-buffer)
        (insert prompt)
        (comint-send-input)))))
</pre>
</div>

<p>
You can bind `kprompt-bard` to any key of your choice and start
interacting with Google bard from the comfort of Emacs' buffer. 
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-ai.html">AI</a> <a href="https://www.birkey.co/tag-emacs.html">emacs</a> </div><div id="archive">
<a href="https://www.birkey.co/archive.html">Other posts</a>
</div>
</div>
<div id="postamble" class="status"><br><center>
	      <div style="display: inline-block; vertical-align:middle;"></div></div>
</body>
</html>
