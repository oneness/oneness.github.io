<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title><![CDATA[BirkeyCo]]></title>
<description><![CDATA[BirkeyCo]]></description>
<link>https://www.birkey.co/</link>
<lastBuildDate>Tue, 22 Apr 2025 12:22:27 -0700</lastBuildDate>
<item>
  <title><![CDATA[Nix: Better way for fun and profit]]></title>
  <description><![CDATA[
<p>
Nix is started in 2003 as a research project aimed to solve the
problem of <b>reliable software deployment</b>. The PhD thesis titled <b>The
Purely Functional Software Deployment Model</b> proposed a novel way of
building software where the final artifact is purely dependent on the
inputs to the build system, which is a pure function in a mathematical
sense. Regardless of where you are in your nix journey, I can't
recommend this paper (<a href="https://edolstra.github.io/pubs/phd-thesis.pdf">thesis</a>) enough. It is very approachable and
worth a read so you learn from first principle of what, why and how
about Nix.
</p>

<p>
Nix is a software build and management system that can replace
traditional package managers, build environments and configuration
tools. Due to the inherent complexity of the problem domain nix is
designed to solve and its long history, it has pretty steep learning
curve but not unsurmountable. One of the common point of confusions is
how the term `Nix` is used in documentations, tutorials and
blogosphere. So let me clarify few terminologies that often gets
overloaded. 
</p>

<ul class="org-ul">
<li><b>Nix:</b> Unless otherwise fully qualified, I use it to mean the
software build and management system.</li>
<li><b>Nix CLI:</b> The nix command line client that one uses to interact with nix.</li>
<li><b>Nix DSL:</b> The domain specific language that nix uses to generate a
software package. I would like to see everyone start using it to
mean the nix language.</li>
<li><b>Flakes:</b> A Nix DSL with number of conventions that is designed to
ease the configuration and discoverability of software packaging lifecycle.</li>
<li><b>NixOS:</b> The final artifact, which is happened to be a Linux
Operating System that is generated by feeding Nix DSL to nix. I will
not be covering it in this blog post.</li>
</ul>

<p>
After few false starts and restarts, below are what I believe to be
better ways for getting started, using nix for fun and profit.
</p>
<div id="outline-container-org2f32676" class="outline-2">
<h2 id="org2f32676">Installation</h2>
<div class="outline-text-2" id="text-org2f32676">
<p>
I have a following bash script to install a specific version so I can
have control over which version to install, what features enable and
disable.
</p>

<div class="org-src-container">
<pre class="src src-bash">#!/usr/bin/env bash
set -Eeuo pipefail

VERSION='2.28.1' # replace it with the latest version
URL="https://releases.nixos.org/nix/nix-${VERSION}/install"
MY_CONF="$HOME/.dotfiles/nix/nix.conf"
sh &lt;(curl --location "${URL}") \
     --daemon \
     --no-channel-add \
     --nix-extra-conf-file ${MY_CONF}
# conf file has this content
experimental-features = nix-command flakes
</pre>
</div>
<p>
The `&#x2013;no-channel-add` and the extra conf file needs some
explanation. Nix called a remote url a channel that gets automatically
installed, where nix uses to retrieve package definitions (Nix DSL) to
manage packages. It introduces a state, which is currently installed
channel url that is outside of Nix DSL, thus defeating the purpose of
reproducibility. It is considered legacy feature and not needed by
flakes, an experimental feature already widely adopted by the
community. So I highly recommend enabling flakes and additional
commands to interact with it.
</p>
</div>
</div>
<div id="outline-container-org2b5adb4" class="outline-2">
<h2 id="org2b5adb4">Using for fun and sanity</h2>
<div class="outline-text-2" id="text-org2b5adb4">
<p>
Every project depends on existing software that is beyond your
control. Nix DSL enables you to declaratively specify your projects
dependencies, a repo or a tar-ball down to the file digest of its
content, which is what gives nix superpowers of being a deterministic
and reproducible package manager. This means that if your inputs stays
the same, nix guarantees that it produces the exact same output
regardless of when and where. Below is a flake that pulls in latest
version of Clojure into your project.
</p>

<div class="org-src-container">
<pre class="src src-nix">{
  # optional attribute
  description = "My awesome Clojure/ClojureScript project";

  # required attribute
  inputs = {
    # nix dsl fns useful for writing flakes
    flake-utils.url = "github:numtide/flake-utils/v1.0.0";
    # Pins state of the packages to a specific commit sha
    pinnedPkgs.url = "github:NixOS/nixpkgs/c46290747b2aaf090f48a478270feb858837bf11";
  };

  # required attribute
  outputs = { self, flake-utils, pinnedPkgs }@inputs :
  flake-utils.lib.eachDefaultSystem (system:
  let pinnedSysPkgs = inputs.pinnedPkgs.legacyPackages.${system};
  in
  {
    devShells.default = pinnedSysPkgs.mkShell {
      packages = [
        pinnedSysPkgs.clojure
      ];

      # commands to run in the development interactive shell
      shellHook = ''
        echo To get Clojure REPL, Run:
        echo clojure
        echo To get ClojureScript REPL, Run:
        echo clj -Sdeps \'{:deps {org.clojure/clojurescript {:mvn/version "1.11.132"}}}\' -M -m cljs.main --repl
      '';
    };
    packages = {
      docker = pinnedSysPkgs.dockerTools.buildLayeredImage {
        name = "My awesome Clj docker image built by nix";
        tag = "latest";
        contents = [pinnedSysPkgs.clojure];
      };
    };
  });
}

</pre>
</div>

<p>
Do not worry too much about not understanding above nix dsl code. The
most important thing to know is that it is nix dsl referred to as a
flake that specifies its inputs and outputs declaratively. Save above
code as `flake.nix`, which is a convention, then run `nix develop` to
get an interactive shell with Clojure in your path. Nix can do way
more than this. However, I recommend you just start with solving
project dependencies problem. Above flake gives you following
benefits:
</p>
<ul class="org-ul">
<li>Ability to pin the exact versions of your project dependencies.</li>
<li>Cross platform development environment that works
both in MacOS and various flavors of Linux.</li>
<li>Determinate and reproducible development environment that
eliminates "it works on my machine" tooling issues.</li>
</ul>
<p>
One important thing to notice here is the way I chose to reference
the url inputs of the flake. I deliberately used tags or commit sha to
prevent the state of the urls (thus the state of the nix DSL) change
under me, which defeats the purpose of having a determinate
and reproducible way to get a development environment. I have
following bash script that prints available tags and corresponding
commit hash:
</p>
<div class="org-src-container">
<pre class="src src-bash"> git_tag_sha () {
   repo="$1"
   echo "********************************************************"
   echo "Available release and commit sha for pinning are:"
   echo "********************************************************"
   printf "\033[1m%-12s %s\033[0m\n" "release" "commit sha"
   curl -s https://github.com/$repo/tags | grep -oP 'href="\K[^"]*(releases/tag|nixpkgs/commit)[^"]*' | awk -F '/' 'NR%2{tag=$NF; next} {printf "%-12s %s\n", tag, $NF}'
   echo
   echo "****************************************************************************"
   echo "Please replace the commit sha of following line to pin pkgs to a commit sha: "
   echo "pinnedPkgs.url = github:$repo/&lt;commit&gt;"
   echo "****************************************************************************"
   echo
}
# You can run it like this:
 git_tag_sha "NixOS/nixpkgs"
</pre>
</div>
</div>
</div>
<div id="outline-container-orgec3469a" class="outline-2">
<h2 id="orgec3469a">Profiting in CI/CD and production</h2>
<div class="outline-text-2" id="text-orgec3469a">
<p>
This is probably one of the most frictionless and rewarding outcome of
using nix. Nix is designed to solve the problem of software deployment
after all but the wholesale adoption in production might prove to be
too much for the final gain. To spare yourself countless hours of
frustration, I highly recommend you start with using it to build
docker image if you happened to use docker and Kubernetes. Nix has
superb built-in support for making the smallest possible docker image
otherwise impossible. Above flake already includes `docker` image as
one of its packages output. Here is how you build and load the docker image:
</p>

<div class="org-src-container">
<pre class="src src-bash">nix build .#docker # the image will be in ./result
docker load &lt; ./result # to get it ready to be deployed
</pre>
</div>

<p>
It is a declarative way (using the power of Nix DSL compared to using
series commands in YAML file) to deterministically reproduce layered
Docker image that saves time and money in your DevOps journey. Have
fun and enjoy!
</p>
</div>
</div>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-nix.html">nix</a> </div>]]></description>
  <category><![CDATA[nix]]></category>
  <link>https://www.birkey.co/2025-04-15-nix:-better-way-for-fun-and-profit.html</link>
  <guid>https://www.birkey.co/2025-04-15-nix:-better-way-for-fun-and-profit.html</guid>
  <pubDate>Tue, 15 Apr 2025 14:30:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Google Bard and Emacs]]></title>
  <description><![CDATA[
<p>
After reading a Google blog post on Bard's increasing ability for
reasoning about source code, I thought I would give it a try. The
issue is that not like OpenAI, Bard currently does not have an http
API that I can use via curl. I googled around and came across the
`bard-rs` project here: <a href="https://github.com/Alfex4936/Bard-rs">https://github.com/Alfex4936/Bard-rs</a>. So I
followed the excellent instruction to get set up using bard from
command line and its is pretty solid. I used following Elisp to use
`bard-rs` from Emacs' compilation buffer here:
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(defun kcompilation-start (cmd name &amp;optional mode)
  (let* ((compile-command nil)
         (compilation-save-buffers-predicate 'ignore)
         (compilation-buffer
          (compilation-start cmd
                             (if (equal mode 'read-only) nil t)
                             (lambda (m)
                               (or (when (boundp 'name)
                                     (format "*%s*" name))
                                   (buffer-name))))))
    (when current-prefix-arg
      (with-current-buffer compilation-buffer
        (switch-to-prev-buffer (get-buffer-window (current-buffer)))))
    (message (format "Running %s in %s ..." cmd name))))

(defun kprompt-bard (&amp;optional p)
  "Prompts for input to send it to `bard` using `bard-rs` in
*bard-prompt* buffer. If mark-active, uses the text in the region
 as the prompt"
  (interactive "P")
  (let* ((bs "bard-prompt")
         (bname (format "*%s*" bs))
         (bname (if (get-buffer bname)
                    bname
                  (progn (kcompilation-start "bard-rs -e ~/.env" bs)
                         bname)))
         (prompt (if mark-active
                     (replace-regexp-in-string
                      "\n"
                      ""
                      (buffer-substring-no-properties (region-beginning) (region-end)))
                   (read-string "AI Chat Prompt: "))))
    (with-current-buffer (pop-to-buffer bname)
      (when p
        (end-of-buffer)
        (insert "!reset")
        (comint-send-input)
        (end-of-buffer)
        (insert prompt)
        (comint-send-input))
      (when (not p)
        (end-of-buffer)
        (insert prompt)
        (comint-send-input)))))
</pre>
</div>

<p>
You can bind `kprompt-bard` to any key of your choice and start
interacting with Google bard from the comfort of Emacs' buffer. 
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-ai.html">AI</a> <a href="https://www.birkey.co/tag-emacs.html">emacs</a> </div>]]></description>
  <category><![CDATA[AI]]></category>
  <category><![CDATA[emacs]]></category>
  <link>https://www.birkey.co/2023-06-18-google-bard-and-emacs.html</link>
  <guid>https://www.birkey.co/2023-06-18-google-bard-and-emacs.html</guid>
  <pubDate>Sun, 18 Jun 2023 10:06:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[AI or not to AI]]></title>
  <description><![CDATA[
<p>
1913 Webster dictionary gives following definition to Artificial Intelligence:
<b>Artificial</b> - 1. Made or contrived by art; produced or modified by
human skill and labor, in opposition to natural; 2. Feigned;
fictitious; assumed; affected; not genuine. 3. Artful; cunning;
crafty. 4. Cultivated; not indigenous; not of spontaneous growth;
<b>Intelligence</b> - 1. The act or state of knowing; the exercise of the
understanding. 2. The capacity to know or understand; readiness of
comprehension; the intellect, as a gift or an endowment. 3. Knowledge
imparted or acquired, whether by study, research, or experience;
general information. Specifically; (Mil.) Information about an enemy
or potential enemy, his capacities, and intentions.
</p>

<p>
Let us read and re-read above definitions and give it a few minutes to
sink in. With our skilled labor, we have managed to produce a very
powerful fictitious software that can understand, produce and reason
about human generated artifacts such as language, images and
videos. Our ability to make it more scalable, more accurate and more
controllable is just a matter of time considering what we have is
already pretty powerful enough. My following interaction with ChatGPT
3.5 is already impressive:
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">[ME]: Explain, then add tests and simplify if possible:
(defun kprompt (&amp;optional p)
  (interactive "P")
  (let* ((bname (if p "*org-ai-on-region*" "*scratch*"))
         (directive "Explain, then add tests and simplify if possible:\n")
         (prompt (if p
                     (buffer-substring (region-beginning) (region-end))
                   (read-string "AI Chat Prompt: "))))
    (with-current-buffer (pop-to-buffer bname)
      (when p
        (erase-buffer)
        (org-mode)
        (setq truncate-lines nil)
        (setq word-wrap t)
        (org-ai--insert-created-timestamp)
        (insert "\n")
        (insert "#+begin_ai\n" "[ME]: " directive prompt "\n" "#+end_ai\n")
        (forward-line -1)
        (org-ai-complete-block))
      (when (not p)
        (beginning-of-buffer)
        (open-line 2)
        (org-ai-prompt prompt)))))

[AI]: This function takes an optional argument, p, which determines whether the user
will be prompted to enter a text or whether the function will use the text highlighted
in the buffer. 

If p is provided, it will create a new buffer with the name "*org-ai-on-region*" and
insert the highlighted text from the current buffer along with a directive. This new
buffer buffer will be formatted using org-mode to allow for better organization of
comprehension text. Finally, it will call org-ai-complete-block to add some
AI-generated text to the prompt.

If p is not provided, it will prompt the user to enter text and then call
org-ai-prompt org-ai-prompt to add some AI-generated text to the prompt.

Tests:

Input:
(kprompt)
Expected Output:
AI Chat Prompt: 

Input:
(kprompt t)
Expected Output:
*org-ai-on-region* buffer created with prompt

Input:
(Highlight "This is a test")
(kprompt t)
Expected output:
*org-ai-on-region* buffer created with "This is a test" text and AI-generated text.

Simplified Code:
The code appears to be relatively straightforward and efficient.
No simplification is needed.
</pre>
</div>

<p>
It understood and reasoned about a piece of code (simple for now but
does not matter as it can get pretty powerful in no time) despite the
fact that it has never seen above code before in its entirety (I am
pretty sure about that since it is a private code and this is the only
time I am making the code public). This degree of intelligence
codified into a software that a few powerful cooperation currently
dominates should be something that keeps every software engineers
awake at night. Not because of its inherent danger or tremendous
productivity boosting ability as folks on the opposite side of
spectrum of current AI debate claimed, but because of the very fact
that every aspect of human lives will be effected by a such a
powerful code like ChatGPT whether we like it or not, and we need
to do whatever we can to ensure it is used for the good of humanity in
general. It is created by humans and should serve humans. Make no
mistake about it. Powerful software systems like that is already used
by big cooperations and rouge states to cajole people into a state of
self censorship if not into a state of heedlessness of its future
implication. Social media, powerful tracking and image recognition
systems are already pervasive in the lives of millions of people that
are being controlled by dictators all around the world (and it is
being exported very actively in the name of economic progress) to
socially engineer people's behaviors that benefits their agenda in
the name of social and economic progress at the very expense of
destroying anyone or anything that is deemed as an obstacle.
</p>

<p>
As a software engineer who have seen the worst of what bad actors can
do with such a powerful systems, I am calling out to all of my fellow
engineers to start thinking about what kind of world we would like our
kids to inherit from us regardless of where you are, who you are and
what is your geopolitical affiliation is. The wave is already there,
and it takes all of us to make sure we are not being social
engineered out of our humanity. I believe in the power of our humanity
to make AI to work for us not the other way around. I registered the
domain <b>www.codeforhumanrights.org</b> few years ago and this might be a
good time to start putting it to a good use. If you are reading this
and feel the need to start doing something, reach out to me via ktuman
at acm dot org.
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-ai.html">AI</a> <a href="https://www.birkey.co/tag-emacs.html">emacs</a> </div>]]></description>
  <category><![CDATA[AI]]></category>
  <category><![CDATA[emacs]]></category>
  <link>https://www.birkey.co/2023-05-14-ai-or-not-to-ai.html</link>
  <guid>https://www.birkey.co/2023-05-14-ai-or-not-to-ai.html</guid>
  <pubDate>Sun, 14 May 2023 09:52:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Atomic commits made easy]]></title>
  <description><![CDATA[
<p>
Code complexity is something we all deal with in our daily work. There
are many tools to helps us manage it. One of the most important one is
to make incremental changes where each change is about <b>one and one
context alone</b> , which is a great definition of <b>an atomic commit</b>. I
do not think I need to convince you about its benefits any further
than what I already have alluded to above, which is worth repeating
here: It helps us contain complexity within our code base. In pursuit
of making it easy for me to do atomic commits, I settled down
following workflow:
</p>
<ul class="org-ul">
<li>Separate changes by its effects. If a change is immutable, that is
to say it is simple refactor or restructure that does not change the
existing behavior, it should be in one commit.</li>
<li>If changes are mutable, that is to say it changes existing behavior,
group them further by their logical context where the context is
about one and one thing alone. This is really crucial since we would
like to make sure every commit can stand on its own and does not
depend on later commits. This gives us the linear append only change
that we can easily keep track of. This might sound a bit strange to
you, but it means that you should not commit a not finished work at
least not push up stream. That also does not mean that you should
not commit your work as often as possible but if you do commit and
end up violating above convention, you should amend/squash your
commits.</li>
</ul>

<p>
Having armed with above convention, I incorporated following tools to
help me to make atomic commits easy:
</p>
<ul class="org-ul">
<li><a href="https://www.gnu.org/software/emacs/"><b>Emacs</b></a></li>
<li><a href="https://github.com/oneness/commit-patch"><b>commit-patch</b></a></li>
<li><a href="https://github.com/oneness/commit-patch/blob/master/commit-patch-buffer.el"><b>commit-patch-buffer</b></a></li>
</ul>

<p>
I am not going to repeat what the excellent <a href="https://porkrind.org/missives/commit-patch-managing-your-mess">blog</a> talked about above
tools here, but it is worth checking it out, and I highly recommend
it. If you happen to use Emacs, here is how you add it to your
config:
</p>

<div class="org-src-container">
<pre class="src src-emacs-lisp">
;; clone above repo in to ~/repos and eval following code
(load-file "~/repos/commit-patch/commit-patch-buffer.el")
(eval-after-load 'diff-mode
  '(require 'commit-patch-buffer nil 'noerror))

</pre>
</div>

<p>
With above configuration, you can M-x vc-diff a file (vc-root-diff for
whole project) then kill, split or edit the resulting hunks using diff
mode's built-in commands and to then hit C-c C-c to commit the
patch. Later if you realized that your commit is not atomic, you can
make further changes and amend previous commit by C-c C-C (note the
upper case C). 
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-vc.html">vc</a> <a href="https://www.birkey.co/tag-emacs.html">emacs</a> </div>]]></description>
  <category><![CDATA[vc]]></category>
  <category><![CDATA[emacs]]></category>
  <link>https://www.birkey.co/2023-03-04-atomic-commits-made-easy.html</link>
  <guid>https://www.birkey.co/2023-03-04-atomic-commits-made-easy.html</guid>
  <pubDate>Sat, 04 Mar 2023 13:20:00 -0800</pubDate>
</item>
<item>
  <title><![CDATA[Notes on StrangeLoop 2022]]></title>
  <description><![CDATA[
<p>
StrangeLoop this year made me feel almost as normal as those during
pre pandemic times especially in terms of size of participants and
sponsors. I actually believe it had the most sponsorship so far among
those I attended over the years. One noticeable company was AWS that a
friend of mine joined earlier this year. So it was pretty exciting to
meet up with him there. As always, the breadths of folks and topics
from all walks of Software Engineering is just excellent this time as
well. I took few notes on the talks that I am able to attend and would
summarize them on few categories below.
</p>

<p>
<b>Dev Experience</b> : I consider observability to be an important part of
 development experience, which is always pushed back as an
 afterthought for almost all the startups that I worked with and I
 know of. The talk "Building Observability for 99% Developers" by Jean
 Yang just resonated with me and I am really glad that her company is
 building tools to make developer experience better using <a href="https://ebpf.io">eBPF</a> that
 has matured in the last few years. It was quite and entertaining talk
 and I highly recommend you check it out. Another talk that I really
 enjoyed is "Workflows, a new abstraction for distributed systems" by
 Dominik Tornow. If you are dealing with the chaos of distributed
 services, the abstraction that he presented make you feel like you
 are working with monolith (oh the happy times :) again with the
 advantage of cloud scalibility.
</p>

<p>
<b>Programming Languages</b> : I personally prefer dynamic languages
 (Clojure to be exact) as my tools of choice for my day to day
 practice of solving problems for people but I do see the benefit of
 type system as a guiding rail when designing an API or better yet
 generating code. You should check out the talk "Codegen with Types,
 for Humans, by Humans" by Matthew Griffith, where he talks about how
 to use types to generate code for human consumption. If you are
 working with (or say fighting with) type system that is complecting
 your business logic/code execution, you should check out the talk
 "Monad I Love You Now Get Out Of My Type System" by Gjeta Gjyshinca,
 where she talks about the platform that helps Scala developer to get
 their type system out of business logic with just five extra
 characters, @node, with a compiler plugin.
</p>

<p>
<b>Data Centric Problem Solving</b> : Strange Loop Conf have always been
 attractive to data centric practices and paradigms and this year was
 no different. There are many talks related to how to generate,
 architect and analyze data. The talk titled "Data-driven
 investigation in defense of human rights" by Christo Buschek is
 presented with very clear and methodical approaches to solve real
 problems we face around the world. I really feel like we need more of
 that type of work where we put technology for the benefit of our
 fellow human beings. I think he should do another presentation next
 year titled "Data-driven investigation in defense of peace and
 opposition of war", which surely makes me sign up for Strange Loop
 for one last time (Next year will be the last time you can experience
 Strange Loop and I highly recommend you attend to see what you have
 been missing).
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-conference.html">conference</a> <a href="https://www.birkey.co/tag-strange-loop.html">strange-loop</a> </div>]]></description>
  <category><![CDATA[conference]]></category>
  <category><![CDATA[strange-loop]]></category>
  <link>https://www.birkey.co/2022-10-08-notes-on-strangeloop-2022.html</link>
  <guid>https://www.birkey.co/2022-10-08-notes-on-strangeloop-2022.html</guid>
  <pubDate>Sat, 08 Oct 2022 14:30:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Automate OpenBSD anonymous public wifi log in]]></title>
  <description><![CDATA[
<p>
Security is somewhat cat and mouse game. This does not mean however
you be careless or just live with what you are handed to when it comes
to protecting yourself from ill-intentioned actors out in the
wild. Generally, I recommend choosing security over convenience, speed
or shiny features for your offline and online computing needs. To
start with, you are much better protected if you start using secure
defaults of the system you are using. For example, Firefox has
<b>HTTPS-Only Mode</b> that you can enable especially if you find yourself
using public wifi. If you happen to use OpenBSD, you are in a treat
:). Below bash script will allow you to log in to public wifi using
random MAC addresses each time you connect to it: <b>NOTE:</b> iwm0 is the
wireless card name on my laptop and you need to replace it with yours.
</p>
<div class="org-src-container">
<pre class="src src-shell">#!/usr/bin/env bash

ssid="$1"
pass="$2"
doas ifconfig iwm0 up
sleep 3
echo Wireless card is up

if [[ -z "$pass" ]]; then
    doas ifconfig iwm0 nwid "$ssid" lladdr random
    echo Joining public $ssid
else
    doas ifconfig iwm0 nwid "$ssid" wpakey "$pass"
    echo Joining private $ssid
fi

sleep 3

doas dhcpleasectl iwm0

echo Renewing inet address
sleep 3

echo Visiting google.com to test connection
proxy=$(curl -s -L -I -o /dev/null -w '%{url_effective}' google.com)

firefox $proxy

</pre>
</div>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-openbsd.html">openbsd</a> <a href="https://www.birkey.co/tag-security.html">security</a> </div>]]></description>
  <category><![CDATA[openbsd]]></category>
  <category><![CDATA[security]]></category>
  <link>https://www.birkey.co/2022-02-05-automate-openbsd-anonymous-public-wifi-login.html</link>
  <guid>https://www.birkey.co/2022-02-05-automate-openbsd-anonymous-public-wifi-login.html</guid>
  <pubDate>Sat, 05 Feb 2022 19:40:00 -0800</pubDate>
</item>
<item>
  <title><![CDATA[OpenBSD 7 Xfce Desktop]]></title>
  <description><![CDATA[
<p>
I blogged previously about why one should use OpenBSD and this time I
would like to document steps to have a fully working Xfce Desktop with
default installation. My goal is to keep the changes minimal only to
absolutely required steps, nothing more nothing less. If you find
steps missing (or did not work as expected) or not necessary, please
drop me a line via k tuman at acm dot org so I can address and update
this blog if needed.
</p>

<ol class="org-ol">
<li><p>
Download the img and make USB boot disk:
</p>
<div class="org-src-container">
<pre class="src src-shell">curl -O https://cdn.openbsd.org/pub/OpenBSD/7.0/amd64/install70.img
sudo dd if=~/Downloads/install70.img of=/path/to/usb
</pre>
</div></li>
<li>Boot from USB disk. Press <b>I</b> and hit enter when you see the
`Welcome to the OpenBSD/amd64 7.0 installation program.` and follow
the prompt. It is pretty straightforward. Once it is done, just
reboot, which will automatically downloads and installs needed
firmwares for your laptop.
--<b>NOTE:</b>&#x2013; You can select whole disk and auto layout if you are not
sure. Using wired connection for network interface is highly recommended.</li>
<li><p>
Once you login, switch to root account, add needed packages and
needed configs like this:
</p>
<div class="org-src-container">
<pre class="src src-shell">su  ## prompts for root password
pkg_add xfce xfce-extras ## install xfce desktop
sed -i 's/xconsole/#xconsole/' /etc/X11/xenodm/Xsetup_0 # no xconcole
usermod -G operator &lt;user name&gt; # so you can use xfce to log out, reboot etc
usermod -G wheel &lt;user name&gt; # so you can use doas
echo "permit persist :wheel" &gt;&gt; /etc/doas.conf # doas = sudo
rcctl enable messagebus ## enable dbus
rcctl start messagebus ## start dbus
rcctl enable apmd ## enable power daemon
rcctl start apmd  ## start power daemon
exit # switch to your user account
echo "exec startxfce4" &gt; ~/.xsession ## auto launchs xfce4 desktop
doas reboot ## restart to have a xfce default desktop
</pre>
</div></li>
</ol>

<p>
<b>Bonus Tips and Tricks</b>
</p>
<ul class="org-ul">
<li><p>
Your wifi most likely will just work. In case if you get unlucky,
here is how you can get it working:
</p>
<div class="org-src-container">
<pre class="src src-shell">doas ifconfig # lists all supported interfaces
doas fw_update # to install missing driver for your card
dmesg | grep pci | grep &lt;wifi card model&gt; # report if not supported
doas ifconfig # again to check if your card listed
doas ifconfig join &lt;Wifi name&gt; wpakey &lt;password&gt; # to join your wifi
# Run following 2 lines if you want to auto join your wifi:
doas echo "join wifiname wpakey password" &gt;&gt; /etc/hostname.&lt;wificardname&gt;
doas echo "dhcp" &gt;&gt; /etc/hostname.&lt;wificardname&gt;
doas sh /etc/netstart # to restart the network
ping openbsd.org # to test your network
</pre>
</div></li>
<li><p>
While default Xfce4 desktop is fully functional out of the box, I
recommend following packages:
</p>
<div class="org-src-container">
<pre class="src src-shell">doas pkg_add xfce4-power-manager xfce4-whiskermenu
ln -s -f yourloginpics ~/.face # profile in whiskermenu and in lock screen
</pre>
</div>
<p>
Add them to the panel and tweak them to your liking. One setting I
highly recommend enabling following in `Window Manager Tweaks`:
</p>
<ul class="org-ul">
<li>[✓] <b>Hide title of windows when maximized</b></li>
</ul></li>
</ul>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-openbsd.html">openbsd</a> </div>]]></description>
  <category><![CDATA[openbsd]]></category>
  <link>https://www.birkey.co/2022-01-29-openbsd-7-xfce-desktop.html</link>
  <guid>https://www.birkey.co/2022-01-29-openbsd-7-xfce-desktop.html</guid>
  <pubDate>Sat, 29 Jan 2022 12:58:00 -0800</pubDate>
</item>
<item>
  <title><![CDATA[Few notes on Strange Loop 2021]]></title>
  <description><![CDATA[
<p>
This year's Strange Loop was my 4th and it was as good as it has been
in the past. One of the main reason I like to go to conferences
especially Strange Loop was to see beyond the state of the art
transmittable knowledge, which is the untransimittable one. In this
age of Google search, Stack Overflow copy/paste and Coding school
driven programming, which has its own place in our industry, we need
to be cognizant of the existence and importance of the
untransimittable part of software engineering knowledge that can only
be acquired by learning from the masters. And Strange Loop has never
failed me so far to provide an opportunity to jolt my brain to find
easier those tacit knowledge that otherwise might have taken me long
winding road to acquire. I would like to present few of those that I
have taken notes so it will help my aspiring fellow engineers.
</p>

<p>
<b>Domain Driven Design</b> : There are numerous books/posts/videos about
 how to do it right and I have been using it with success for the last
 few years. However, I have always been little bit unclear about how I
 measure its benefit within my engineering team. I got the `AHA`
 moment when second day keynote put up a quote on its slide stating
 that 'Small change in product (Domain), should result in small change
 in the code (implementation)'. Now, I know how to measure if we are
 doing it right or wrong in my team.
</p>

<p>
<b>API Design</b> : There is a talk about using Rust's type system in
 aiding you to design a robust API that does validation and error
 reporting right. While that talk focus on how Rust type system is
 tremendously useful to library (API) designer, what I see from that
 talk is way beyond just helpfulness of a well designed type system,
 which is a languages ability to allow you to specify your system's
 interfaces exactly as you intended. If you are not using one of those
 languages (Rust, F#, Ada and Clojure &#x2026; any language that allows you
 specify interfaces) in your library/API work, you should be checking
 them out to see what you are missing (also remember to keep an eye
 for what you are loosing. It is all about trade offs).
</p>

<p>
<b>Dependencies</b> : This is a topic that is very dear to day to day
 practice considering my current preferred tool of choice (Clojure and
 ClojureScript). The branchstack talk triggered sort of `AHA` moment
 for me in treating the entire state of your system (code) vs the
 state of your outside dependencies. I'd like to think of them as your
 internal state vs external state. I have been advocating and
 practicing a sort of convention your system should only be just three steps
 away from being able to be worked upon, which is:
</p>
<div class="org-src-container">
<pre class="src src-shell">git clone &lt;your_system_x&gt; &amp;&amp; make deps &amp;&amp; make run
</pre>
</div>
<p>
Note that it does not have to be git and make. Any tool of your
choice will do. The idea is that as a project owner, it is your
responsibility to make sure that your system workflow is easily
reproducible and those tools should be treated as first class citizen
as your system logic code.
</p>

<p>
Again, those kind of tacit knowledge can only be learned by being in
the presence of crafts people and having actually conversation with
them in close vicinity. I have enjoyed all the talks that I attended
and even more so the hallway and lunch table conversation. And I am
looking forward to Strange Loop 2022 already :).
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-conference.html">conference</a> <a href="https://www.birkey.co/tag-strange-loop.html">strange-loop</a> </div>]]></description>
  <category><![CDATA[conference]]></category>
  <category><![CDATA[strange-loop]]></category>
  <link>https://www.birkey.co/2021-12-12-few-notes-on-strange-loop-2021.html</link>
  <guid>https://www.birkey.co/2021-12-12-few-notes-on-strange-loop-2021.html</guid>
  <pubDate>Sun, 12 Dec 2021 11:49:00 -0800</pubDate>
</item>
<item>
  <title><![CDATA[Why Eshell? - Part 5]]></title>
  <description><![CDATA[
<p>
One of the feature of Eshell that took me sometime to really
appreciate is its built-in ability to emulate Plan9 smart Shell. It
allows you to run a script or a command, run it again by just hitting
enter key after you modify it, say you made a mistake or want to
change part of it using Emacs editing power. You might say that you
can do same thing in any terminal using your up arrow key and command
line editing. But I challenge you to try it until you fully realize
the advantage you have vs regular terminal. Below is a simple screen
recording to show you what I mean:
</p>


<figure id="orgf663aab">
<img src="https://www.birkey.co/images/eshell-plan9-smart-shell.gif" alt="eshell-plan9-smart-shell.gif">

</figure>

<p>
I recommend you read following post to learn more about smart shell
and more about eshell including aliases:
<a href="https://masteringemacs.org/article/complete-guide-mastering-eshell">https://masteringemacs.org/article/complete-guide-mastering-eshell</a>.
</p>

<p>
This concludes my `Why Eshell` series. Hope you find it useful and
happy Eshelling!
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-eshell.html">eshell</a> <a href="https://www.birkey.co/tag-emacs.html">emacs</a> </div>]]></description>
  <category><![CDATA[eshell]]></category>
  <category><![CDATA[emacs]]></category>
  <link>https://www.birkey.co/2021-08-01-why-eshell-part-5.html</link>
  <guid>https://www.birkey.co/2021-08-01-why-eshell-part-5.html</guid>
  <pubDate>Sun, 01 Aug 2021 09:58:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Why Eshell? - part 4]]></title>
  <description><![CDATA[
<p>
Since eshell buffer is just a regular emacs buffer, we have all of the
emacs power at our disposal. In part 3 of my post, I briefly alluded
to multiple terminal management by just using few lines of elisp and
all without using any third party packages. I am posting the main elisp
function for posterity here:
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(defun krun (cmd)
  (interactive
   (list
    (ido-completing-read
     "Enter cmd to run (append ##name for buffer name): "
     (let ((history nil))
       ;; We have to build up a list ourselves from the ring vector.
       (dotimes (index (ring-length keshell-history-global-ring))
	 (push (ring-ref keshell-history-global-ring index) history))
       ;; Show them most-recent-first.
       (setq history (nreverse history))))))
  (let* ((cmds (split-string cmd "##"))
	 (tag (or (-&gt; cmds second)
		  "kshell"))
	 (buff-name (-&gt; tag s-chomp s-trim)))
    (kshell cmd buff-name)))
</pre>
</div>
<p>
The above function (along with those from the previous post) will
allow you to do following:
</p>
<ul class="org-ul">
<li>Start a new shell with a specific name by just appending
##buffer-name after the command</li>
<li>Run a command from history or new command in a dedicated eshell
buffer, which defaults to <b>kshell</b>. You can override as any name you
want.</li>
<li>Use all hotkeys, interactive lisp functions as you would for regular
emacs buffer. For example, you can do buffer switching, ibuffer
management, isearch, protect a buffer from being killed, etc.</li>
</ul>

<p>
Following demonstrates above cases I am talking about:
</p>


<figure id="org7fae62d">
<img src="https://www.birkey.co/images/eshell-buffer-management.gif" alt="eshell-buffer-management.gif">

</figure>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-eshell.html">eshell</a> <a href="https://www.birkey.co/tag-emacs.html">emacs</a> </div>]]></description>
  <category><![CDATA[eshell]]></category>
  <category><![CDATA[emacs]]></category>
  <link>https://www.birkey.co/2021-07-17-why-eshell-part-4.html</link>
  <guid>https://www.birkey.co/2021-07-17-why-eshell-part-4.html</guid>
  <pubDate>Sat, 17 Jul 2021 09:43:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Why Eshell? - Part 3]]></title>
  <description><![CDATA[
<p>
If you have been following my `Why Eshell` series, you might be
wondering about interactive ido completion for eshell. Since Eshell
buffer is just a regular emacs buffer, we can compose few emacs
builtin functionalities to bend it to our command line work flow.
Following is all the code you need. Note that it is heavily commented
so you can understand what is happening.
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(defun kshell-with-name (&amp;optional name)
  ;; creates an eshell buffer with `kshell' as the default name. Take
  ;; optional name to override
  (let ((m (-&gt;&gt; (or name "kshell")
		(format "*%s*"))))
    (if (get-buffer m)
	(pop-to-buffer m)
      (progn
	(eshell)
	(rename-buffer m)))))

(defun kshell (&amp;optional cmd buff-name send-input)
  ;; interactive fn that you can call via M-x or hotkey. It detects
  ;; current project root to start eshell buffer if no `buff-name' is
  ;; given. You can control how the `cmd` gets insert only or insert
  ;; and executed using `send-input` flag. Ex. Useful for further
  ;; editing.
  (interactive)
  (let ((dir (projectile-project-root))) ;; you need projectile
    (if buff-name
	(kshell-with-name buff-name)
      (kshell-with-name))
    (eshell/clear-scrollback)
    (insert (format "cd %s" (or dir "~/")))
    (eshell-send-input)
    (insert (format "%s" cmd))
    (when send-input (eshell-send-input))))

(defun krun (cmd)
  ;; eshell command history with ido completion. Assign it to a hot
  ;; key say, F12 and you will get a search-able command history that
  ;; you can execute just by doing ido interactive search.
  (interactive
   (list
    (ido-completing-read
     "Enter cmd to run (append ##name for buffer name): "
     (let ((history nil))
       ;; We have to build up a list ourselves from the ring vector.
       (dotimes (index (ring-length keshell-history-global-ring))
	 (push (ring-ref keshell-history-global-ring index) history))
       ;; Show them most-recent-first.
       (setq history (nreverse history))))))
  (let* ((cmds (split-string cmd "##")) ;; you need s.el lib
	 (tag (or (-&gt; cmds second)
		  "kshell"))
	 (buff-name (-&gt; tag s-chomp s-trim)))
    (kshell cmd buff-name)))
</pre>
</div>
<p>
Here is the screen recording in action:
</p>


<figure id="org5159e5f">
<img src="https://www.birkey.co/images/eshell-ido-interactive.gif" alt="eshell-ido-interactive.gif">

</figure>

<p>
I am using F12 to invoke `krun` and my cross session eshell history
shows up in the minibuffer where I can use ido completion to select a
command that I can run. As an added benefit, above code allows one to
bring a eshell buffer with specific name by adding ##name at the end
of the command if one wants to have the command run in a dedicated
buffer.
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-eshell.html">eshell</a> <a href="https://www.birkey.co/tag-emacs.html">emacs</a> </div>]]></description>
  <category><![CDATA[eshell]]></category>
  <category><![CDATA[emacs]]></category>
  <link>https://www.birkey.co/2021-07-10-why-eshell-part-3.html</link>
  <guid>https://www.birkey.co/2021-07-10-why-eshell-part-3.html</guid>
  <pubDate>Sat, 10 Jul 2021 10:18:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Why Eshell? - Part 2]]></title>
  <description><![CDATA[
<p>
Among many reasons of why I use eshell as my main terminal, I listed
following in part 1 of my `Why Eshell?` series blog post. I am listing
it here for posterity:
</p>
<ol class="org-ol">
<li><b>Long running command notification and time</b></li>
<li><b>Cross session history</b></li>
<li><b>Interactive ido completion</b></li>
<li><b>Unified interface (shell prompt buffer as regular emacs buffer)</b></li>
<li><b>Plan9 Style Shell prompt (Think of it as bash REPL)</b></li>
<li><b>Multiple terminal management</b></li>
<li><b>Super charge bash with elisp</b></li>
<li><b>Eshell aliases that puts bash aliases to shame :)</b></li>
</ol>
<p>
I addressed first point here: <a href="https://www.birkey.co/2021-06-20-why-eshell-part-1.html">notification and time</a>. Let me address
second point, which is sharing eshell history across many terminal
sessions.
</p>
<div class="org-src-container">
<pre class="src src-elisp">(defvar keshell-history-global-ring nil
  "The history ring shared across Eshell sessions.")

(defun keshell-hist-use-global-history ()
  "Make Eshell history shared across different sessions."
  (unless keshell-history-global-ring
    (when eshell-history-file-name
      (eshell-read-history nil t))
    (setq keshell-history-global-ring
	  (or eshell-history-ring (make-ring eshell-history-size))))
  (setq eshell-history-ring keshell-history-global-ring))
;; Following hook enables it
(add-hook 'eshell-mode-hook 'keshell-hist-use-global-history)
;; Following removes the hook
(remove-hook 'eshell-mode-hook 'keshell-hist-use-global-history)
</pre>
</div>
<p>
After evaluating above 12 lines of elisp, you will have a list that
holds all the eshell entries across sessions, which you can persist
into a history file (just uses bash history file) and can even share
it across machines over network. This opens up a whole new
possibilities of completions, deduplication and multiple eshell
buffer management goodness, which I will cover in the next few parts
of `Why Eshell?` posts. So stay tuned and happy eshelling!
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-eshell.html">eshell</a> <a href="https://www.birkey.co/tag-emacs.html">emacs</a> </div>]]></description>
  <category><![CDATA[eshell]]></category>
  <category><![CDATA[emacs]]></category>
  <link>https://www.birkey.co/2021-06-27-why-eshell-part-2.html</link>
  <guid>https://www.birkey.co/2021-06-27-why-eshell-part-2.html</guid>
  <pubDate>Sun, 27 Jun 2021 08:37:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Why Eshell? - Part 1]]></title>
  <description><![CDATA[
<p>
From time to time, I got asked why I use eshell as my main terminal.
There are multiple reasons I do so and covering all of them in one
post would be too long. Instead, I would like to start with a high
level bullet points and address each one in a separate blog post with
working code examples where I can point my coworkers and friends to
them so they can pick and choose as they wish.
</p>
<ol class="org-ol">
<li><b>Long running command notification and time</b></li>
<li><b>Cross session history</b></li>
<li><b>Interactive ido completion</b></li>
<li><b>Unified interface (shell prompt buffer as regular emacs buffer)</b></li>
<li><b>Plan9 Style Shell prompt (Think of it as bash REPL)</b></li>
<li><b>Multiple terminal management</b></li>
<li><b>Super charge bash with elisp</b></li>
<li><b>Eshell aliases that puts bash aliases to shame :)</b></li>
</ol>
<p>
Let us start with how you can accomplish the first item from the list
above. Following 18 lines of elisp will give you the super power of:
</p>
<ul class="org-ul">
<li>How long a command took to run as if you typed in <b>time &lt;command&gt;</b></li>
<li>Notify you that the long running command finished in x second even
if you switch away from Emacs saving you the trouble of constantly
checking back. As a bonus, you can set the notification threshold
for long running commands that you want to run async.</li>
</ul>
<div class="org-src-container">
<pre class="src src-elisp">;; eshell time and notification
(defvar-local eshell-current-command-start-time nil)

(defun eshell-current-command-start ()
  (setq eshell-current-command-start-time (current-time)))

(defun eshell-current-command-stop ()
  (when eshell-current-command-start-time
    (let ((elapsed-time (float-time
			 (time-subtract (current-time)
					eshell-current-command-start-time))))
      (if (&gt; elapsed-time 30)
	  (tooltip-show (format "Finished in: %.0fs" elapsed-time))
	(eshell-interactive-print
	 (format "Time: %.0fs\n" elapsed-time))))
    (setq eshell-current-command-start-time nil)))

(defun eshell-current-command-time-track ()
  (add-hook 'eshell-pre-command-hook #'eshell-current-command-start nil t)
  (add-hook 'eshell-post-command-hook #'eshell-current-command-stop nil t))

;; This line below installs time tracking and notification
(add-hook 'eshell-mode-hook #'eshell-current-command-time-track)
;; Once you eval above snippet in emacs, fire up M-x eshell, and type:
sleep 40
;; You can switch away from emacs and will be notified that above
;; command took 40s to run
;; To uninstall
;; (remove-hook 'eshell-mode-hook #'eshell-current-command-time-track)
</pre>
</div>
<p>
Try doing above with some bashrc voodoo or plug-in that you have no
control over. I have been there and done that and it is one of many
reasons why I use eshell now. I hope someone finds it useful to his or
her command line work flow. Happy eshelling!
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-emacs.html">emacs</a> <a href="https://www.birkey.co/tag-eshell.html">eshell</a> </div>]]></description>
  <category><![CDATA[emacs]]></category>
  <category><![CDATA[eshell]]></category>
  <link>https://www.birkey.co/2021-06-20-why-eshell-part-1.html</link>
  <guid>https://www.birkey.co/2021-06-20-why-eshell-part-1.html</guid>
  <pubDate>Sun, 20 Jun 2021 14:21:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Let and Binding macros in Clojure]]></title>
  <description><![CDATA[
<p>
Clojure has number special forms. Among them are <b>let</b> and
<b>binding</b> that are implemented as macros. For new comers to Clojure,
above can be confusing to understand, which I hope to address in this
blog post. If you have read "Programming Clojure" book, you might be
thinking that it is easy to use them correctly considering following
straightforward example:
</p>

<div class="org-src-container">
<pre class="src src-clojure">(def x 7) ;; bind the var x to the value 7
(defn print-x [x]
  (println x))

(let [x 9]
  (print-x)) ;; prints 7

(binding [x 9]
  (print-x)) ;; prints 9
</pre>
</div>
<p>
Why? Because <b>let</b> creates a lexical scoped vars, which is local to
the code block or functions where it is initially defined while <b>def</b>
creates a global var that is visible to all functions under the
namespace that you are in. Therefore, in the example above, <b>let</b> just
created a new "x" with the value of 9. But it is not local to the
function "print-x". That is to say, "print-x" have no knowledge of the
local scoped binding that is created by <b>let</b>. <b>binding</b> macro instead
creates a new binding for the already existed var, "x" with the value
of 9. Since "print-x" is evaluated within the <b>binding</b> form, the
newly bound value is visible to any chained calls within the form. All
nice and easy. However, it is not that obvious to understand and use
them correctly. Look at following example:
</p>
<div class="org-src-container">
<pre class="src src-clojure">(def x 7)
(def y 9)

(let [x 5 y x] y) ;; returns 5
(binding [x 5 y x] y) ;; returns 7
</pre>
</div>
<p>
<b>let</b> example is just fine. It created a new var "y" with the value of
5 bound to it. But what is going on with the <b>binding</b> example? If we
dig little deeper to Clojure API doc, we learn that the new bindings
in <b>binding</b> are made in parallel, not sequential as it is in <b>let</b>.
Therefore, existing var "y" gets bound to the root binding of "x" not
the overshadowed value of "x", which is the case in the <b>let</b> example.
OK, so far so good. Let us look at another example:
</p>
<div class="org-src-container">
<pre class="src src-clojure">(defn print-x [&amp; args]
  (println "print-x prints: " args))
(defn print-y [&amp; args]
  (println "print-y prints: " args))
(let [print-x print-y] (print-x 123)) ;; print-y prints: (1 2 3)
(binding [print-x print-y] (print-x 123)) ;; print-y prints: (1 2 3)
(binding [print-x print-y] #(print-x 123)) ;; prints
					     ;; cryptic "#&lt;user$eval__28$fn__30
					     ;; user$eval__28$fn__30@bdb503&gt;"
((binding [print-x print-y] #(print-x 123))) ;; print-x prints: (1 2 3)
</pre>
</div>
<p>
All the lines but the last two are pretty straight forward. But how
about the last line? Shouldn't it call "print-y" function? Not really.
It is because the anonymous function is evaluated outside of the
<b>binding</b> form. The "#&lt;user$eval_<sub>28</sub>$fn_<sub>30</sub>
user$eval_<sub>28</sub>$fn_<sub>30</sub>@bdb503&gt;" is an indication that anonymous function
did not get evaluated. The extra parens evals above form. Ok,
now, how do you make sure it evaluates within the <b>binding</b> form? Just
enclose the anonymous function within parenthesis. What do we learn
from all of the above? Here are the summary that helps one use <b>let</b>
and <b>binding</b> correctly:
</p>

<ul class="org-ul">
<li>Use <b>binding</b> only if you are trying to alter a behavior dynamically
for special-vars that is already defined. Enclose your special vars
within * as recommended by idiomatic clojure to make your intent
clear.</li>
<li>Use <b>let</b> for locally scoped vars and avoid shadowing already
defined vars.</li>
<li>Remember <b>let</b> binding is sequential and <b>binding</b> binding is done in parallel.</li>
<li>Pay close attention to the scope of the <b>binding</b> form. Any
expression that is not evaluated inside the form, will not see the
binding. That is to say, binding in <b>binding</b> form is thread local
starting from the <b>binding</b> form until it ends including any
expression that is chained within the form, which is what the
thread-local are all about.</li>
<li>Lastly avoid using <b>binding</b> as much as possible. I have seen many
production bugs related to issues I outlined here.</li>
</ul>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-clojure.html">clojure</a> </div>]]></description>
  <category><![CDATA[clojure]]></category>
  <link>https://www.birkey.co/2021-06-13-let-and-binding-macros-in-clojure.html</link>
  <guid>https://www.birkey.co/2021-06-13-let-and-binding-macros-in-clojure.html</guid>
  <pubDate>Sun, 13 Jun 2021 11:35:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[On programming style]]></title>
  <description><![CDATA[
<p>
I am pretty excited to learn that Strange Loop is happening this
year! It is one of the few technical conference that I always
recommend to my fellow teammates. What is more exciting are the
sessions including few keynotes. What this has to do with the
topic of the blog post, which is on programming style, you say? If you
squint at the sessions, the author of <b>Exercises in Programming Style</b>
is the first keynote speaker. It is one of the best book on programming I
have ever read in recent years. I am not going to spoil it here with
summary or gist but I'd like share few take home points I really liked
about the book.
</p>

<ul class="org-ul">
<li>Having a clear, well understood programming problem throughout the
book: given a text file, we want to display the N (e.g. 25) most
frequent words and corresponding frequencies ordered by decreasing
value of frequency. Once the understanding what problem we are
dealing with out of the way, the remaining is just choosing a style
to solve it, which the book does fantastic job to explain. It even
has full source code in the book.</li>
<li>Concise and clear way of making the reader understand many programming
techniques that one might otherwise gets really confused. For
example, Monads, CPS (continuation passing style), FRP and many
others.</li>
<li>Have you ever wondered how neural networks (NN) works? Second
edition have you covered with clear explanation and code as she has
done with many concepts from the first edition.</li>
</ul>

<p>
I strongly recommend the book to both novice or pros alike. It is a
book that you rarely see in terms of style and clarity with full
working code. We really need this kind of books more to have
programming accessible and understood by more people. I do believe it
is a classic. If you are planning to attend Strange Loop, remember to
say hello and thank her for it.
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-books.html">books</a> </div>]]></description>
  <category><![CDATA[books]]></category>
  <link>https://www.birkey.co/2021-06-06-on-programming-style.html</link>
  <guid>https://www.birkey.co/2021-06-06-on-programming-style.html</guid>
  <pubDate>Sun, 06 Jun 2021 10:30:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[less is literally more]]></title>
  <description><![CDATA[
<p>
As an Emacs user, your muscle memories constantly remind you of
certain behavior of it when you had to use other Unix tools. I was
recently viewing a large file using <b>less</b> and searched for
<b>ErrorCode</b> by just typing <b>errorcode</b> and surprised to find that it
did not find any match. Then, I searched by typing <b>ErrorCode</b> and it
did find a match containing the word, which reminded me of the fact
that <b>less</b> by default is case sensitive. I then set out to find if I
can tell <b>less</b> to ignore case by reading man pages. I am pleasantly
surprised to read following:
</p>
<div class="org-src-container">
<pre class="src src-bash">-i or --ignore-case
	      Causes searches to ignore case; that is, uppercase and lowercase
	      are  considered identical.  This option is ignored if any upper-
	      case letters appear in the search pattern; in other words, if  a
	      pattern  contains  uppercase  letters, then that search does not
	      ignore case.
</pre>
</div>
<p>
That is exactly how Emacs isearch behaves by default. I added
following alias to my bash config to make above the default for less.
</p>
<div class="org-src-container">
<pre class="src src-bash">alias less='less -i'
</pre>
</div>

<p>
Once again, less is <b>literally</b> more and you could do more using less.
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-shell.html">shell</a> </div>]]></description>
  <category><![CDATA[shell]]></category>
  <link>https://www.birkey.co/2021-03-27-less-is-more-literally.html</link>
  <guid>https://www.birkey.co/2021-03-27-less-is-more-literally.html</guid>
  <pubDate>Sat, 27 Mar 2021 10:37:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[cURl to the rescue]]></title>
  <description><![CDATA[
<p>
A web application tinkerer deals with malformed inputs, faulty
networks, buggy software and everything in between. One tool that
saved the day on more than one occasion is: <b>cURL</b>, which should be
under every engineers' arsenal. Following are two examples how it
proved to be just the right tool to reach for.
</p>

<p>
Among many micro services writtent in Clojure, one of them exposed
following logic via a REST API:
</p>
<ul class="org-ul">
<li>Take a shortened URL, expand it to find the actual
URL it is pointing to, and parse URL param to generate a JSON object
of k/v to return to the caller.</li>
</ul>

<p>
One of our client reported a bug where their Ad data dashboard did not
show up one day. Looking at the log trace, I realized that above
service might be failing. I had a choice of starting a full suite of
our services to reproduce it or just using cURL from the terminal to
find out what the Ad URL expanded to. Here is an example:
</p>
<div class="org-src-container">
<pre class="src src-bash">curl -ILs https://bit.ly/2MSn9Xm
</pre>
</div>
<p>
Following is the output:
</p>
<pre class="example">
| HTTP/2                       | 301                                                               |               |     |      |          |     |
| server:                      | nginx                                                             |               |     |      |          |     |
| date:                        | Sun,                                                              | 10            | Jan | 2021 | 22:59:35 | GMT |
| content-type:                | text/html;                                                        | charset=utf-8 |     |      |          |     |
| content-length:              | 152                                                               |               |     |      |          |     |
| cache-control:               | private,                                                          | max-age=90    |     |      |          |     |
| content-security-policy:     | referrer                                                          | always;       |     |      |          |     |
| location:                    | https://www.birkey.co/2020-12-26-ETC-principle-to-ground-all.html |               |     |      |          |     |
| referrer-policy:             | unsafe-url                                                        |               |     |      |          |     |
| via:                         | 1.1                                                               | google        |     |      |          |     |
| alt-svc:                     | clear                                                             |               |     |      |          |     |
| HTTP/2                       | 200                                                               |               |     |      |          |     |
| server:                      | GitHub.com                                                        |               |     |      |          |     |
| content-type:                | text/html;                                                        | charset=utf-8 |     |      |          |     |
| last-modified:               | Mon,                                                              | 28            | Dec | 2020 | 05:11:32 | GMT |
| access-control-allow-origin: | *                                                                 |               |     |      |          |     |
| etag:                        | 5fe96904-2616                                                     |               |     |      |          |     |
| expires:                     | Sun,                                                              | 10            | Jan | 2021 | 23:09:36 | GMT |
| cache-control:               | max-age=600                                                       |               |     |      |          |     |
| x-proxy-cache:               | MISS                                                              |               |     |      |          |     |
| x-github-request-id:         | 8A36:98E4:92929:AC1C3:5FFB86D7                                    |               |     |      |          |     |
| accept-ranges:               | bytes                                                             |               |     |      |          |     |
| date:                        | Sun,                                                              | 10            | Jan | 2021 | 22:59:36 | GMT |
| via:                         | 1.1                                                               | varnish       |     |      |          |     |
| age:                         | 0                                                                 |               |     |      |          |     |
| x-served-by:                 | cache-pao17466-PAO                                                |               |     |      |          |     |
| x-cache:                     | MISS                                                              |               |     |      |          |     |
| x-cache-hits:                | 0                                                                 |               |     |      |          |     |
| x-timer:                     | S1610319576.187969,VS0,VE28                                       |               |     |      |          |     |
| vary:                        | Accept-Encoding                                                   |               |     |      |          |     |
| x-fastly-request-id:         | 64128c1c6f907b66fc189d5c3cbb298b2c7e9eb7                          |               |     |      |          |     |
| content-length:              | 9750                                                              |               |     |      |          |     |
</pre>

<p>
The options <b>-ILs</b> tells cURL to query resource headers with location
information in silent mode. After seeing the location information of
the client's Ad URL, I was able to pinpoint the missing url param from
the source data that our client is expecting. Once I informed this
info to our client, they are able to fix their own issue with grace.
</p>

<p>
Second time cURL came to the rescue is when a developer from
my team reached out to me for a mysterious bug he was experiencing. An
API call was failing for 50% of the time with truncated response that
was causing error on his application. Not knowing anything about the
application much, I asked him to call the API using cURL to eliminate
the possibility of OS network related issues. Once I know that the API
work is working 100% of the time via cURL, I narrowed the issues down
to the application code. The application is written in Node and
following are abbreviated version of how the JS code looks like:
</p>
<div class="org-src-container">
<pre class="src src-javascript">function getFoo(){
  return axios.get(urlFoo)
}

function getBar(url){
  return axios.get(url)
}

function getFooBar(){
 var foo = getFoo(); //block until we have a result
 // this line below was failing due to malformed foo becuase it is truncated
 var url = "magicUrl" //parse `foo`, construct url
 var bar = getBar(url)
 return parse(bar)
}

</pre>
</div>
<p>
My teammate said that he did try increasing the timeout of the `axios`
library but it did not help. I asked him to see if `axios` have
some configuration setting related to buffer size or connection, and he
confirmed that it does have `connection reuse` setting where it is
default value are `false`. I asked him to try setting it to `true`,
which he did and voila, API call went through with 100% success
rate. Now, our problem is solved and we can move on with our
lives.
</p>

<p>
I just want to convince you how usefull <b>cURL</b> command is and you
should use it whenever you can. I might write a post in the future on
why the response was getting truncated and why reusing the connection
helped solve the issue.
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-curl.html">curl</a> </div>]]></description>
  <category><![CDATA[curl]]></category>
  <link>https://www.birkey.co/2021-01-10-curl-to-the-rescue.html</link>
  <guid>https://www.birkey.co/2021-01-10-curl-to-the-rescue.html</guid>
  <pubDate>Sun, 10 Jan 2021 12:21:00 -0800</pubDate>
</item>
<item>
  <title><![CDATA[ETC - The principle to guide engineering]]></title>
  <description><![CDATA[
<p>
If you are just curious about the ETC principle to ground all other
principles of software engineering, you can scroll all the way down of
this post to find out what I meant by ETC. If you know what ETC stands
for and are already grounding your engineering efforts, you can just
skip this post and go on with your MIT (most important task). However,
If you are skeptical, which you always should be, you might want to
read on to learn why.
</p>

<p>
As an Engineer, our primary function on daily basis is to come up
with a working solution to a specific problem that arose out of
need from our <b>users</b>. I highlight the word user here since the user
could be our end user, could be our fellow engineers, or could just be
ourselves. If you have been in the industry for a while, you might
have been exposed to plethora of must follow principles and practices
from existing literature, which I categorize as `transmittable`
knowledge. Apart from that, there is another type of knowledge that I
would like to classify as `untransmittable` where you have to
experience it to make it your own. Those two types of knowledge
corresponds to how we learn new things: 1. We read transmittable
knowledge from various sources 2. We bring them into our practice to
form our deep understanding of it. Only then, we are able to utilize
our newly learned knowledge effectively to achieve our end result,
which is by the way to meet the needs of our fellow <b>users</b> as apposed
to the need of certain systems. Now, let us stack ETC principle
against three of the most well known engineering paradigms so we are
always grounded in our approach to utilizing them.
</p>

<div id="outline-container-org7665c2a" class="outline-2">
<h2 id="org7665c2a">Monolith vs Microservice</h2>
<div class="outline-text-2" id="text-org7665c2a">
<p>
We have come a long way since the 1950s in our approach to different
design and architectural paradigms. Over the last 10 years or so, we
all have been preached to about how great Microservice is and have drunk its
Kool-Aid. It has penetrated engineering organizations to such a degree
that it has become our new hammer. Now all of a sudden, we start
waking up to its trade offs and even going back to old monolith
architecture. What happened? We just did not ground ourselves when
we made a decision to adopt microservice style. The question we should
have asked ourselves before committing to microservice or monolith is:
How it enables us to make whatever we are doing easy to change? Does
monolith style make our system easy to change? Maybe. Does
microservice approach enables us easy to change our system? Maybe. So
the definite answer to both questions is "it depends". So what should
be the basis of our decision to go with one way or the other? Maybe
an example in order to drive my point here. Let's say you're
designing an e-commerce system. It has catalog, checkout and shipping
components. Does putting all of the components into one service make
the system easy to change for you? May be it will if you are the only
person or your team are the only team working on it. Does putting all
of the components into separate services make the system easy to
change? May be it will if you have three separate teams working on
them.
</p>
</div>
</div>

<div id="outline-container-orgcf7d58f" class="outline-2">
<h2 id="orgcf7d58f">Top down vs bottom up design</h2>
<div class="outline-text-2" id="text-orgcf7d58f">
<p>
I have seen teams swear by one way or the other on this matter. From
time to time, someone comes along to preach one over the other
declaring the other approach is dead or should just be avoided. Every
time when I face such a design issue, I always ask myself this
question over and over again: Does top down or bottom up design
enables me or my team to respond to change? Most of the time, I end up
choosing both approaches because it helps me to focus on making the
system easier to change. I tend to use following rule of thumb. When I
have clear mental model, I use the bottom up approach so I can create
layers of abstractions to compose better, which in turn enables me to
make changes easier. When I have a high level of domain clarity, I
tend to start with top down design because it helps me to focus on not
that clear pieces in isolation, which in turn makes changes a lot more
manageable.
</p>
</div>
</div>

<div id="outline-container-org7672d35" class="outline-2">
<h2 id="org7672d35">OO vs FP paradigm</h2>
<div class="outline-text-2" id="text-org7672d35">
<p>
I was preached and have been preaching OO style of programming
paradigm from since my college days and well into the early years of my
profession. Then FP became the new style (old became new?) and all OO
programming languages started to add more FP style constructs. Now we
see debates over why FP is superior over OO and should be used over
all cost claiming that OO is responsible for all the mess that we
created over the last 20 years or so. Now, I came to realize that it
is not this or that paradigm that is responsible for all the issues we
created. Rather, it is the blind adoption of them by us as
practitioners. Let us think about a minute what OO have given us when
we started to adopt it: The ability to structure, reuse and share code
across systems. Essentially, we were able to build/change information
systems faster and easier than ever before. However, it did not hold
up well against ETC principle with its humongous frameworks and so
called best practices. Now, FP is in its renaissance and being
preached as the savior at the cost of relegating OO to its
oblivion. OO is a great tool set in our arsenal for certain types of
problem domain and SmallTalk is an example of how it should be
practiced. FP is another excellent way of approaching to engineering
problem in that it encourages to treat systems as referential data
transformation pipeline. Does it inherently make the system easy to
change? Not really. We are quite capable of making a spaghetti mess
out of FP as much as we have done with OO. See a pattern here? ETC
principle grounds your choice of paradigm into its proper place: Is
x helping you to make changes easier? If not, then x most likely not
best route for you.
</p>

<p>
I can go on and on with arguing ETC be the test to pass for all of the
paradigms and even development approaches such as TDD, BDD and
DDD. For example, If your code is easy to change, it will most likely
be easy to test, maps most likely well with your domain and most
likely models use cases better. You can adopt any approach or
principles such as SOLID principle if you consistently ask yourself:
Does this really helps me to make changes easier? If it passes this
test, adopt it, if not avoid it.
</p>

<p>
It is not my intention to make you dogmatic about <b>Easy To Change</b>
(ETC) principle but rather to convince yourself to have one principle
to ground all other aspects of your engineering endeavors. Happy
engineering and never forget to have and share fun coding!
</p>
</div>
</div>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-engineering.html">engineering</a> </div>]]></description>
  <category><![CDATA[engineering]]></category>
  <link>https://www.birkey.co/2020-12-26-ETC-principle-to-ground-all.html</link>
  <guid>https://www.birkey.co/2020-12-26-ETC-principle-to-ground-all.html</guid>
  <pubDate>Sat, 26 Dec 2020 15:06:00 -0800</pubDate>
</item>
<item>
  <title><![CDATA[One command to drive all]]></title>
  <description><![CDATA[
<p>
Over the years, I got to learn various package managers either due to tinkering with work or home infrastructure. I need to keep remembering if I am on Ubuntu, OSX or on OpenBSD if I want to install/remove/list/update packages. wouldn't it be nice if all I need to remember is just one command <b>pkg</b> with following neumonic options?
</p>
<ul class="org-ul">
<li><b>s</b> for searching for a package</li>
<li><b>i</b> for install a package</li>
<li><b>r</b> for removing a package</li>
<li><b>l</b> for listing installed packages</li>
<li><b>c</b> for checking/cleaning packages</li>
</ul>

<p>
Following shell script does exactly that. And it could also serve as your reference to all unix package managers as an added benefit.
</p>
<div class="org-src-container">
<pre class="src src-Shell">#!/bin/sh
# One pkg command to rule them all
if [ -z "$1" ]
then
    echo "Usage: pkg &lt;i(nstall)|r(emove)|s(earch)|u(pdate)|l(ist)&gt;"
else
    os=$([[ -f /etc/os-release ]] &amp;&amp; grep ^ID= /etc/os-release | cut -d = -f 2 || echo `uname`)
    echo --------------------- $os --------------------
    command=$1
    shift
    case $os in
	*OpenBSD*)
	    case $command in
		i)
		    pkg_add $@
		    ;;
		r)
		    pkg_delete $@
		    ;;
		s)
		    pkg_info -Q $@
		    ;;
		u)
		    pkg_add -u $@
		    ;;
		l)
		    pkg_info -mz
		    ;;
		c)
		    pkg_check
		    ;;
	    esac
	    ;;
	*Arch)
	    case $command in
		i)
		    yay -S $@
		    ;;
		r)
		    yay -Rs $@
		    ;;
		s)
		    yay -Ss $@
		    ;;
		u)
		    yay -Syyu $@
		    ;;
		l)
		    yay -Q $@
	    esac
	    ;;
	*solus*)

	    case $command in
		i)
		    sudo eopkg it $@
		    ;;
		r)
		    sudo eopkg remove $@
		    ;;
		s)
		    sudo eopkg search $@
		    ;;
		u)
		    sudo eopkg up
		    ;;
		l)
		    sudo eopkg list-installed
	    esac
	    ;;
	VoidLinux)
	    case $command in
		i)
		    sudo xbps-install $@
		    ;;
		r)
		    sudo xbps-remove -R $@
		    ;;
		s)
		    sudo xbps-query -Rs $@
		    ;;
		u)
		    sudo xbps-install -Su
		    ;;
		l)
		    sudo xbps-query -l
		    ;;
		c)
		    sudo xbps-remove -Oo
		    ;;
	    esac
	    ;;
	pureos|PureOS|debian|Ubuntu)
	    case $command in
		i)
		    sudo apt-get install $@
		    ;;
		r)
		    sudo apt-get remove $@
		    ;;
		s)
		    apt-cache search $@
		    ;;
		u)
		    sudo apt-get update &amp;&amp; sudo apt-get upgrade
		    ;;
		l)
		    sudo apt list --installed
		    ;;
		c)
		    sudo apt-get autoremove
		    ;;
	    esac
	    ;;
	darwin*|Darwin*)
	    case $command in
		i)
		    brew install $@
		    ;;
		r)
		    brew remove $@
		    ;;
		s)
		    brew search $@
		    ;;
		u)
		    brew update
		    ;;
		l)
		    brew list
		    ;;
		c)
		    brew cleanup
		    ;;
	    esac
	    ;;
	*)
	    echo "Unknown OS. Please add it to $(basename "$0") pkg function"
    esac
fi
</pre>
</div>

<p>
If you happen to use Emacs and Eshell, you can just use following alias to get going:
</p>
<div class="org-src-container">
<pre class="src src-Shell">alias pkg ./pkg '$*'
</pre>
</div>
<p>
Eshell aliases are great. You can pass arguments to them just prefixing aliases with '$*' as I did above. Try doing same with bash alias, you are out of luck and you have to write shell functions be able to do that. Enjoy!
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-shell.html">shell</a> </div>]]></description>
  <category><![CDATA[shell]]></category>
  <link>https://www.birkey.co/2020-03-10-one-command-to-drive-all.html</link>
  <guid>https://www.birkey.co/2020-03-10-one-command-to-drive-all.html</guid>
  <pubDate>Tue, 10 Mar 2020 09:46:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Self documenting Makefile]]></title>
  <description><![CDATA[
<p>
One of the pain points of starting a new project or even hacking on
existing project is to know where to start. One can start with
documentation, test cases or even running it to see the logs and
stacktraces (Stracktrace way is one of my favourite and you can tell a
lot about code flow, organzation and you can even find un-handled bugs
that way, which is a topic of its own for a blog post). Each language
brings in its own set of tools that you need to know before you
getting familiar with the code base. You might add `README` or some
other documents to ease the pain but it might get stale overtime. One
convention that I have been using, which has paid off with any project
or teams that I have collaborated, are following simple conventions:
</p>
<ul class="org-ul">
<li>A project should have a `Makefile` with following targets:
<ul class="org-ul">
<li><b>setup</b> : Should take care of env configs</li>
<li><b>deps</b>  : Should take care of handling all the project dependencies</li>
<li><b>unit-test</b> : Should have local tests</li>
<li><b>integration-test</b> : Should have non local tests</li>
</ul></li>
<li>This Makefile should be self documenting:
<ul class="org-ul">
<li>It should have <b>help</b> as the default target that explains what the project is about and how to run it</li>
<li>It should be self documenting, meaning each target should have it is own description as to what it does and possible why it does it the way it is.</li>
</ul></li>
</ul>

<p>
Above might sound a lot to ask but it is really trivial to do those with just following make file:
</p>

<div class="org-src-container">
<pre class="src src-Shell">.PHONY: help
help: ## This is a cool project. It does great things to help humanity move forward.
        @echo 'usage: make [target] ...'
        @echo
        @echo 'Targets Depends Description' | column -t -s ' '
        @echo '------- ------- -----------' | column -t -s ' '
        @egrep '^(.+)\:?.+\ ##\ (.+)' ${MAKEFILE_LIST} \
        | column -t -s ':#' | sed 's/Makefile  //'

setup: ## Sets up all that are needed start working on the project.
        @echo Setting up...
        # Put you logic here
        @echo Setting up done.

deps: setup ## Pulls in all required dependencies
        @echo Pulling all project dependencies

unit-test: deps ## Runs local tests
        @echo Running unit-tests...
        # Put your run unit-tests logic here
        @echo unit-tests done.

integration-test: deps ## Runs non local tests
        @echo Running integration-tests...
        # Put your run integration-tests logic here
        @echo integration-tests done.
</pre>
</div>

<p>
The presence of above Makefile should not be underestimated. It will allow yourself and your fellow developers to dive into any project with just one liner like this:
</p>

<div class="org-src-container">
<pre class="src src-Shell">git clone &lt;project&gt; &amp;&amp; cd project &amp;&amp; make deps
</pre>
</div>

<p>
Would not that be wonderful if every project just follow simple conventions like this so you have less obstacle to start or dive into a project? It has benefited me and my team over the years and hope you see the benefit for yourself.
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-makefile.html">Makefile</a> </div>]]></description>
  <category><![CDATA[Makefile]]></category>
  <link>https://www.birkey.co/2020-03-05-self-documenting-makefile.html</link>
  <guid>https://www.birkey.co/2020-03-05-self-documenting-makefile.html</guid>
  <pubDate>Thu, 05 Mar 2020 10:52:00 -0800</pubDate>
</item>
<item>
  <title><![CDATA[OpenBSD laptop for the paranoid]]></title>
  <description><![CDATA[
<p>
<b>Disclaimer</b>: This is not a post about UNIX variants flame war. It is not my intention to recruit OpenBSD converts either as no one has influenced me to switch to it after 10 years of distro hopping. The main reasons I am using OpenBSD as my daily driver on both of my laptops (Thinkpad X220 and XPS 13 9365) are: <b>Security</b>, <b>Stability</b>, and <b>Frugality</b>.
</p>
<div id="outline-container-orge7546b5" class="outline-2">
<h2 id="orge7546b5">Security</h2>
<div class="outline-text-2" id="text-orge7546b5">
<p>
I am software generalist who knows enough about system (OS,Network and Application) security to be paranoid not just about online systems, which is far from enough to keep ourselves secure, but also on-prem system such as Operating Systems we all rely on for keeping us safe. While Linux could be made as secure as OpenBSD after much tinkering and tweaking, OpenBSD is more secure by default installation. Following quote from <a href="https://www.openbsd.org/">https://www.openbsd.org/</a> is very telling:
</p>
<blockquote>
<p>
Only two remote holes in the default install, in a heck of a long time!
</p>
</blockquote>
<p>
That quote is for what OpenBSD team calls base file set that includes the kernel and base system. Security is the utmost priority for packages being included in the port tree as well. For example, Chromium comes with `&#x2013;enable-unveil` support, which means that it can only access `~/Downloads` folder to mitigate the attack surface if your browser ever gets hijacked.
</p>
</div>
</div>
<div id="outline-container-org83844ce" class="outline-2">
<h2 id="org83844ce">Stability</h2>
<div class="outline-text-2" id="text-org83844ce">
<p>
OpenBSD favors stability over new features. Once installed and configured to your liking, it just stays out of your way allowing you focus on your task at hand. You will not see nagging notifications demanding you to click on installing updates. You can just setup a cron to run `syspatch` to bring in security fixes whenever and however you like. Releases are scheduled for every 6 months in a predictable way so you are in control to plan it ahead. I am running 6.6 release and following errata proves my point: <a href="https://www.openbsd.org/errata66.html">https://www.openbsd.org/errata66.html</a>
</p>
</div>
</div>
<div id="outline-container-org12eac79" class="outline-2">
<h2 id="org12eac79">Frugality</h2>
<div class="outline-text-2" id="text-org12eac79">
<p>
Wikipedia has the best definition for this and I believe it genuinely applies to the Philosophy of OpenBSD project. `Less is more` is a pretty well known Unix tradition and the command `less` (which is a replacement of early UNIX command `more`) is seen in every UNIX variants. OpenBSD is not the most user friendly Unix out there not even among BSD flavors. It is targeted towards security and resource savvy power users who wants have control over every piece of software running on their system. Every line of code is audited for frugality and not needed code is removed. Development is not driven by any cooperate or financial interest as apposed to the Operating System development from big Corporations such as Microsoft, Apple and Google. You can use your old hardware as long as it meets your needs and will not find yourself at the mercy of them nagging you upgrade your hardware let alone your system so often.
</p>

<p>
All in all, it gives you a piece of mind compared to any OS out there when it comes to knowing you are safe by default. If you would like to know more about why OpenBSD, you can visit this site for technical details:
<a href="https://why-openbsd.rocks/fact/">https://why-openbsd.rocks/fact/</a>
</p>

<p>
I am currently running OpenBSD 6.6 on Thinkpad X220 (everything work out of the box) and Dell XPS 13 2 in 1 9365 (all works except for suspend - same as some leading Linux distros). The installation process is not that complicated (mostly you just except the default prompt by hitting enter) but does need some config to make it to your liking. I might blog about the installation process and list my configs for `X` and `cwm` in the future.
</p>
</div>
</div>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-openbsd.html">OpenBSD</a> </div>]]></description>
  <category><![CDATA[OpenBSD]]></category>
  <link>https://www.birkey.co/2020-02-15-openbsd-laptop-for-the-paranoid.html</link>
  <guid>https://www.birkey.co/2020-02-15-openbsd-laptop-for-the-paranoid.html</guid>
  <pubDate>Sat, 15 Feb 2020 18:12:00 -0800</pubDate>
</item>
<item>
  <title><![CDATA[Atreus62 - Best portable mechanical keyboard]]></title>
  <description><![CDATA[
<p>
As a professional programmer, we spend a lot of time with our
keyboards. Having a good ergonomic keyboard is extremely important to
avoid RSI. Since I started learning more about mechanical and
ergonomic keyboards couple of years ago, I have experimented with many
of them - different models, layouts, and switches. Finally, I settled
down with following two: 
</p>
<ul class="org-ul">
<li><a href="https://kinesis-ergo.com/shop/advantage2/">Kinesis Advantage2</a></li>
<li><a href="https://shop.profetkeyboards.com/product/atreus62-keyboard">Profet Atreus62</a></li>
</ul>

<p>
Kinesis one needs couple of weeks to get used as apposed to the Profet
Atreus62 one, which took me few hours. They both uses brown switches,
Kinesis uses Cherry brown, Atreus62 uses Gateron brown. While there
are differences in terms of the point of actuation, peak and tactile
noise based on their spec, I personally did not feel strongly enough
to tell the difference so your mileage may vary. Both of them are very
easy to configure to your liking. Kinesis have done a great job when
it comes to how key mapping is done. Here is how you do it:
</p>
<ul class="org-ul">
<li>Just press both `progm` + F12 together to have it enter remap mode</li>
<li>Then, press the source key you want to move, release it, then press the
destination key that you want to have the source key moved.</li>
<li>Press `progm` to return to normal mode (exits from remap mode).</li>
</ul>

<p>
Atreus62 is a bit involved but it is a joy to hack on it. It uses open
source firmware called `QMK` and you can read more about it here:
<a href="https://docs.qmk.fm/#/">https://docs.qmk.fm/#/</a>. The documentation is great and strongly
recommend you check them out. It is a bit overwhelming and you could
get lost among so much details. The easiest way to start configuring
are to follow these steps:
</p>
<ul class="org-ul">
<li>Go to <a href="https://config.qmk.fm/#/atreus62/LAYOUT">https://config.qmk.fm/#/atreus62/LAYOUT</a> and shuffle keys
around to your liking.</li>
<li>Then download `KEYMAP ONLY`, which gives you `keymap.c`,
`layers.json` and `readme.md`.</li>
<li>Unzip them to a folder say `MyAtreus62Layout`.</li>
<li>Clone QMK Firmware: <a href="https://github.com/qmk/qmk_firmware/">https://github.com/qmk/qmk_firmware/</a></li>
<li>Once cloned, run `./util/qmk-install.sh` from within cloned folder.</li>
<li>Copy `MyAtreus62Layout` folder into `/keyboards/atreus62/keymaps/`
folder within the cloned folder.</li>
<li>Run `make atreus62:MyAtreus62Layout`.</li>
<li>It will generate `atreus62<sub>MyAtreus62Layout.hex</sub>` firmware file.</li>
<li>Use qmk-toolbox GUI found here:
<a href="https://github.com/qmk/qmk_toolbox/releases/">https://github.com/qmk/qmk_toolbox/releases/</a> to flash the firmware.</li>
</ul>

<p>
<b>NOTE:</b> Remember to put your keyboard in flash mode by pressing a thin
paper clip through a tiny hole on the back of the keyboard. 
</p>

<p>
One you go through, above process, you will easily find that editing
the `keymap.c` file is the easiest way to arrange keys. All you need
is the key codes that you can find on the online GUI layout
editor. Once you edit keymap files using your favorite editor, save it
and run the above make command to generate the firmware to flash
it. You can also version control the keymap files in case you want to
share or change it later. Here is my layout if you are curious:
<a href="https://drive.google.com/open?id=1M6x73xg2kAfkL8AvSM31X8MpW3pPlXcX">https://drive.google.com/open?id=1M6x73xg2kAfkL8AvSM31X8MpW3pPlXcX</a>
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-keyboard.html">keyboard</a> </div>]]></description>
  <category><![CDATA[keyboard]]></category>
  <link>https://www.birkey.co/2019-09-07-atreus62---best-portable-mechanical-keyboard.html</link>
  <guid>https://www.birkey.co/2019-09-07-atreus62---best-portable-mechanical-keyboard.html</guid>
  <pubDate>Sat, 07 Sep 2019 13:49:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Why Emacs]]></title>
  <description><![CDATA[
<p>
I have been thinking about writing up my experience of using Emacs and
its positive influence on me as a Software Craftsman over the last 10
years or so. Over the weekend, I came across a a blog post by the CTO
of a company, who put it very well that have really resonated with
me. It is a great read, not too long not too short, that I strongly
recommend you go ahead read and come back here to continue with the
rest of what I had to say. Here is the link: <a href="https://www.fugue.co/blog/2018-08-09-two-years-with-emacs-as-a-cto.html">Two Years With Emacs as a
CEO (and now CTO)</a>. 
</p>

<p>
So I am not going to repeat what he said about Emacs and why he still
loves to use it to get things done. I am going to add following points
on top of what he wrote there:
</p>
<div id="outline-container-orgba850c8" class="outline-2">
<h2 id="orgba850c8">Emacs is a great workbench</h2>
<div class="outline-text-2" id="text-orgba850c8">
<p>
I see Emacs as an extremely well designed workbench that will evolve
with you as your work environment, technology and paradigms
change. Emacs is a live programming environment where you can change
every aspects of its functionalities, be it a simple text editing to a
complex work flow where you can interact with many external
systems. One of a startup that I worked had a mode where we have
interacted with our live system written in Clojure via its CLI
interface using `comint-mode`, which you should really checkout if you
are not familiar with it. You can use Emacs as the client with uniform
interface to many of the CLI, API and even for <a href="https://en.wikipedia.org/wiki/Application_binary_interface">ABI</a>. For example `EXWM`,
which is an Window Manager, is a great example.
</p>
</div>
</div>
<div id="outline-container-orge8be3a5" class="outline-2">
<h2 id="orge8be3a5">Emacs is a great structured and unstructured text manipulation library</h2>
<div class="outline-text-2" id="text-orge8be3a5">
<p>
This is what I personally like a lot about Emacs. As a programmer, we
work with manipulating text all the time. Yes, there are great text
Editors out there, which by the way I have used all of them myself
before seeing the light of using Emacs. But I see all other
editors/IDEs as a framework for the things they set out to do rather
than a library that I can compose to solve a particular problem at
hand. For example, I can use `smartparens` package for structured text
editing of Clojure code.
</p>
</div>
</div>
<div id="outline-container-org9296094" class="outline-2">
<h2 id="org9296094">Emacs helps you focus</h2>
<div class="outline-text-2" id="text-org9296094">
<p>
In this day of our age where everything tries to grab your constant
attention, Emacs stands out as the most distraction free environment
to be in. One might argue that Emacs user spends way more time
configuration management, which is definitely true when you are just
getting started with any new toolbox, I found I spend very little time
with configuration or keeping it up to date. Once you are familiar with
Emacs help system and built in Documentation, You can be pretty much
on your own when it comes to how much you spend on customization. It
is this freedom you get from using Emacs where you are in charge as to
how much customization you would like. The reason I say Emacs helps
you focus is due to the fact that you have the freedom to make it an
distraction free writing/coding/communication environment to get done
what matters the most to you and have a lot of fun along the way.
</p>
</div>
</div>
<div id="outline-container-org3a474d0" class="outline-2">
<h2 id="org3a474d0">Emacs has a learning curve</h2>
<div class="outline-text-2" id="text-org3a474d0">
<p>
Yes, I do acknowledge that Emacs has a learning curve. However, most
of it is due to the wrong approach we tend to take when encountering an
unknown. On hindsight, I wish I had following approach, which I do now
all the time:
</p>
<ol class="org-ol">
<li>Start with getting familiar with Emacs terminology such as windows,
buffers and frames etc. The builtin documentation is great for that
and it is just C-h i (Hit Control and letter `h` at the same time,
then hit `i`, which stands for info). To read Emacs' manual just
enter `m` and select `Emacs` from minibuffer. Hmm, you might be
wondering what is minibuffer, let us use this approach to find
out. Press following C-h i m key sequence and type `Minibuffer` and
hit enter. Voila, you are reading all about `Minibuffer` from the
official Emacs manual. No other application that I have used comes
close to the level of Emacs in terms of self documentation.</li>
<li>Start with the goal of getting something done. I have two example
that every programmer will benefit from learning: `Magit` and
`Org-mode`. While you need to install `magit-mode`, which is a
Emacs interface to git CLI, `org-mode` is built in. You will be
surprised to find that it makes your git journey so much fun or
your note organization so much enjoyable. I made the mistake of
trying to memorize hot keys as much as I can before learning the
hard truth of learning one key at a time as needed bases. I
strongly recommend the only hot key you need at the beginning is
`M-x`, where you just type a command so Emacs can execute for
you. For Example, if you would like open (it is `visit` in Emacs
speak) a file, just type `M-x` and type `file` then press tab key,
select `find-file` in the completion buffer, now you can choose a
file name from within the directory that you are in. It is just an
example but knowing the fact that every action you perform in Emacs
invokes an command, which is just an elisp function, is a very
powerful realization. That means you can write an elisp function to
have Emacs do whatever you like. You can also lookup what a command
does using C-h f, then typing the name of the command. For example,
C-h f then, type `org-insert-link` then enter and read on&#x2026;</li>
<li>I advise against starting with Emacs using other's configuration
including Emacs that comes with pre-configuration. As I have
mentioned earlier, Emacs is a great library where you can pick and
choose to fit your work style. You will loose this great aspects if
you start with other's way of configuring/composing it. If you had
to just start with a minimal config, put this in your `init.el`
file and start changing/adding/organizing configs as you see
fit. For example:</li>
</ol>
<div class="org-src-container">
<pre class="src src-emacs-lisp">;; Emacs reads init.el file located in ~/.emacs.d at startup
;; bootstrap el-get
(add-to-list 'load-path "~/.emacs.d/el-get/el-get")
(unless (require 'el-get nil 'noerror)
  (with-current-buffer
      (url-retrieve-synchronously
       "https://raw.githubusercontent.com/dimitri/el-get/master/el-get-install.el")
    (goto-char (point-max))
    (eval-print-last-sexp)))

;; Initialize available packages first
(package-refresh-contents t)

;; The only package you need to get started
(el-get-bundle smex
  (progn
    (require 'smex)
    (global-set-key (kbd "M-x") 'smex)))
</pre>
</div>
<p>
Above snippets sets you up to use `El-get`, a great package manager
that I came to rely over the years and have never failed me. It also
pulls in the only package you had to have before getting started,
`smex` that makes the only command `M-x` you need much more
intuitive. Then say if you want to try `magit`, just type M-x
el-get-install, then `magit`. El-get will download it and install it
so you can starting using it in your git projects. Once you can find
your way around Emacs, you can start your journey of how best
organize your config/customization as you go along. I use just one
org file for it and you might or might not like it. Here is the file
in its entirety if you are interested: <a href="./static/config.html">My config snapshot</a>
</p>
</div>
</div>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-emacs.html">emacs</a> </div>]]></description>
  <category><![CDATA[emacs]]></category>
  <link>https://www.birkey.co/2019-08-04-why-emacs.html</link>
  <guid>https://www.birkey.co/2019-08-04-why-emacs.html</guid>
  <pubDate>Sun, 04 Aug 2019 12:43:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Thoughts on Elixir Community by a Clojure Developer]]></title>
  <description><![CDATA[
<p>
I have been building systems in Clojure/ClojureScript for the the last
7 years or so. I enjoy using it to solve day to day problems. It is
still my go-to language of choice and I love the fact that it guides me
to think about problem at hand with very data centric way. As a tiny
example of this, consider a feature where you need to toggle the sort
ordering:
</p>
<div class="org-src-container">
<pre class="src src-clojure">(defn toggle-order [order]
  (order {:asc :desc
	  :desc :asc}))
</pre>
</div>
<p>
It is tiny but mighty. There is no if/else/case etc and it is easy to
read, which is extremely important as your program grows due to needed
complexity. Speaking of being <b>easy to read</b>, I could not help but to
quote following from SICP book:
</p>
<blockquote>
<p>
Our design of this introductory computer-science subject reﬂects two
major concerns. First, we want to establish the idea that a computer
language is not just a way of gettng a computer to perform operations
but rather that it is a novel formal medium for expressing ideas about
methodology. <b>Thus, programs must be written for people to read, and
only incidentally for machines to execute.</b> Second, we believe that
the essential material to be addressed by a subject at this level is
not the syntax of particular programming-language constructs, nor
clever algorithms for computing particular functions efficiently, nor
even the mathematical analysis of algorithms and the foundations of
computing, but rather the techniques used to control the intellectual
complexity of large software systems.
</p>
</blockquote>

<p>
For me, Using Clojure and Datomic professionally has been a game
changer not only in terms of being more problem solving focused but
more importantly a paradigm shift for taming domain complexity. It has
helped me deliver robust, high performance systems within time and
budget. However, having bitten by half baked distributed systems made
up of tiny services done as afterthoughts, I have always been on the
lookout for more robust distributed system development story. Then I
found <b>Elixir</b>, a functional language running on Erlang VM called
<b>BEAM</b>. After spending some time attending ElixirConf US and couple of
meetups in <b>ErlangElixirSF</b>, I am posting what I really liked about
Elixir community that Clojure Community might benefit:
</p>

<ul class="org-ul">
<li>Elixir community has a strong focus on few important projects in
their ecosystem, namely <b>Elixir the language and its build tool-
Mix</b>, <b>Pheonix Framework</b>, <b>Nerve</b>, <b>Ecto</b>, and <b>absinthe - The
GraphQL toolkit for Elixir</b>.</li>
<li>Elixir community is pretty mature in terms of keeping the core
language small and extensible, which is abundantly clear from the
creator of Elixir, Jose Valim's 2018 ElixirConf US keynote.</li>
<li>Elixir community is super focused on Documentation and Developer
happiness by having great tooling and convention that they all love
and agreed upon such as <b>mix format</b></li>
</ul>

<p>
I hope someone from both community find above helpful.
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-clojure.html">clojure</a> <a href="https://www.birkey.co/tag-elixir.html">elixir</a> </div>]]></description>
  <category><![CDATA[clojure]]></category>
  <category><![CDATA[elixir]]></category>
  <link>https://www.birkey.co/2019-02-02-clojure-and-elixir.html</link>
  <guid>https://www.birkey.co/2019-02-02-clojure-and-elixir.html</guid>
  <pubDate>Sat, 02 Feb 2019 10:29:00 -0800</pubDate>
</item>
<item>
  <title><![CDATA[Datafy and tap> in Clojure 1.10]]></title>
  <description><![CDATA[
<p>
I noticed couple of new features being added to Clojure 1.10. One is
<b>tap</b>, which is added to the core ns, and the other is <b>datafy</b>, which
is added to clojure.datafy ns.  
</p>

<p>
<b>tap</b> essentially is an atom holding set of fns of single arity, which
will be asynchronously called on any value you you send via
<b>tap&gt;</b>. You can add a single arity fn to the <b>tap</b> via <b>(add-tap f)</b>
and remove the fn via <b>(remove-tap f</b>).  Note that you have to
remember the fn you added so you can remove it. Otherwise, you have no
way of removing the fn, which is an inconvenience but there might be a
reason why it is the way it is. I am not sure about its intended use
cases but I know it comes handy when you have a set of transformation
(<b>important: order of those transformation should not matter</b>) that you
would like to apply to any value asynchronously. I can think of
following uses cases for tap:
</p>
<ul class="org-ul">
<li>Collecting some sort of diagnostic information about running system.</li>
<li>Streaming serious of values to be processed and routed to a sink somewhere.</li>
<li>May be used (rather abused) to execute some code? hope not.</li>
</ul>
<p>
Enough being said, let us see with a simple example to cover first
uses case I said above. 
</p>
<div class="org-src-container">
<pre class="src src-clojure">(def context (StringBuilder.))

(defn -&gt;context [x]
  (doto context
    (.append x)))

;; Then let us add above fn to the tapset
(add-tap -&gt;context)
;; Then from any where of our running code, we can do:
(tap&gt; "******* tap start ********\n ")
(tap&gt; "runing.......................\n")
(tap&gt; "******* tap end **********\n ")

;; It will be executed in a separate dedicated thread and will not
;; block or interfere with our running code. Then we print out the context:
(str context)
;; which results in:
;;******* tap start ********
;; runing.......................
;;******* tap end **********

;; Remember to remove the -&gt;context fn once you are done with that session:
(remove-tap -&gt;context)
;; If there is no fn added to the tap, any values you send to tap will be discarded.
(tap&gt; "your magic") ;; your magic will be discarded.

</pre>
</div>

<p>
The other one I noticed is <b>datafy</b>, which I am more excited about. I
am already using it to find out about java classes members, methods
and its object graph. Let us take a java class <b>String</b> as an example.
</p>
<div class="org-src-container">
<pre class="src src-clojure">(require '[clojure.datafy :as d])
(d/datafy String) ;; which will print all about its members in a nice clojure ds

;; let us write an fn to give use any member that we would like to find more about:
(defn member-lookup [class member]
  (-&gt;&gt; class
       d/datafy
       :members
       (filter (fn [[k v]] (= (symbol member) k)))))
;; then use it to find about "intern"
(member-lookup String "intern")
;; returns:
([intern
  [{:name intern,
    :return-type java.lang.String,
    :declaring-class java.lang.String,
    :parameter-types [],
    :exception-types [],
    :flags #{:public :native}}]])

;; One can learn a lot about this method from above ds. "intern" is a
;; public native method that takes no argument, called on string object
;; and returns string like this:
(.intern "test") ;; =&gt; "test"

</pre>
</div>

<p>
This means we can use above information to create Clojure fns on the
fly for java inter-op. One great use case would be to generate Clojure
fns out of AWS Java SDK, which I might do if time permits.
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-clojure.html">clojure</a> </div>]]></description>
  <category><![CDATA[clojure]]></category>
  <link>https://www.birkey.co/2018-10-26-datafy-and-tap%3E-in-clojure-1.10.html</link>
  <guid>https://www.birkey.co/2018-10-26-datafy-and-tap%3E-in-clojure-1.10.html</guid>
  <pubDate>Fri, 26 Oct 2018 11:19:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Debug VoidLinux unresolvable lib issue]]></title>
  <description><![CDATA[
<p>
I have been a happy user of <b><a href="https://voidlinux.org/">VoidLinux</a></b> for about a year now and so
far have had almost no glitches whatsoever except for updating a year
old version of it installed on one of my spare laptop. The issue started as following:
</p>
<div class="org-src-container">
<pre class="src src-shell">xbps-install -Su
# resulted in following:
# mozjs: broken, unresolvable shlib `libicu.so'
# Transaction aborted due to unresolved shlibs.
</pre>
</div>
<p>
I do not now about you but I usually start with a google search of
what I think is somewhat general terms in my error message, which is
<i><b>"Transaction aborted due to unresolved shlibs"</b></i> in my case. Searching
with the above term came up with number of results and all point to
the build system is still running. You can check the status of it
here: <a href="https://build.voidlinux.eu/waterfall">Void Build Status</a>, which I did find that all is green and
idle. So it did not help me resolve my issue. Then, I decided to do
one more search with <i><b>"mozjs: broken, unresolvable shlib
`libicu.so'"</b></i>, which is more specific to the state of my box only but
that did not help me go anywhere. Then I decided to debug it
myself. Following is my commandline session how I resolved it:
</p>
<div class="org-src-container">
<pre class="src src-shell"># Ran the command again to make sure I have above issue 
xbps-install -Su
# again resulted in following:
# mozjs: broken, unresolvable shlib `libicu.so'
# Transaction aborted due to unresolved shlibs.
# Notice the /*mozjs*/, which is my clue. Then I did:
xbps-query -Rs mozjs
# from the output, I confirmed that it was not installed on my box,
# which is my second clue to check if my repos url are
# up-to-date. Remember it is a year old version of VoidLinux.  I
# noticed from the output of xpbs-install -u, that the
# void-repo-nonfree url does indeed point to an old url. So, I did:
xbps-remove void-repo-nonfree &amp;&amp; xbps-install void-repo-nonfree
# to make sure my repo url is up-to-date. Then it is time to clean my
# repo cache and remove any packages that might be orphened since my
# repo url is pointing to a different url now. Using manpages for
# xpbs-remove, I can do above with:
xbps-remove -Oo
# Then I ran:
xbps-install -Su
# Voila!, My one year old box is up-to-date without any issues now.
# After all of this, I just made an one liner alias in my shell config:
alias c='xbps-remove void-repo-nonfree &amp;&amp; xbps-install void-repo-nonfree &amp;&amp; xbps-install -Su 
</pre>
</div>

<p>
So no love lost for VoidLinux and it is still as awesome as ever. Just
to recap steps that I took to solve the issue:
</p>
<ol class="org-ol">
<li>Start using more general term to do a google search then narrow it
to specific ones. If it works, you save time and unneeded effort.</li>
<li>Check for the problem package reported. Is it installed? If yes,
try removing or updating it to see if it resolves your issue.</li>
<li>If you do not see the package installed, it might be repo url +
orphaned package issue. So update the repo url, remove orphan
packages and rebuild the cache.</li>
</ol>

<p>
If you tried all of the above and your issue still did not get
resolved, you might want to post it in VoidLinux forum for help. 
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-voidlinux.html">VoidLinux</a> </div>]]></description>
  <category><![CDATA[VoidLinux]]></category>
  <link>https://www.birkey.co/2018-10-20-debug-voidlinux-unresolvable-lib-issue.html</link>
  <guid>https://www.birkey.co/2018-10-20-debug-voidlinux-unresolvable-lib-issue.html</guid>
  <pubDate>Sat, 20 Oct 2018 13:53:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Visualize Google search results from Clojure REPL]]></title>
  <description><![CDATA[
<p>
While back when I was learning Clojure, I have written a small lib
that allows me directly generate bar chart out of google search
results from Clojure. I updated it with latest deps and added a fn to
save the bar-chart to a png file. You can checkout the project here:
<a href="https://github.com/oneness/gcount">https://github.com/oneness/gcount</a>.  Here is a one liner to get you
going:
</p>
<div class="org-src-container">
<pre class="src src-shell">git clone git@github.com/oneness/gcount.git &amp;&amp; cd gcount &amp;&amp; lein repl
</pre>
</div>
<p>
Once you are in repl, you can type following:
</p>
<div class="org-src-container">
<pre class="src src-clojure">(search-view-terms ["Clojure Programming" "Elixir Programming" "Elm Programming"])
</pre>
</div>
<p>
Above will produce something like this:
<img src="https://www.birkey.co/images/google-search-result.png" alt="google-search-result.png">
</p>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-clojure.html">clojure</a> </div>]]></description>
  <category><![CDATA[clojure]]></category>
  <link>https://www.birkey.co/2018-10-04-visualize-google-search-results-from-clojure-repl.html</link>
  <guid>https://www.birkey.co/2018-10-04-visualize-google-search-results-from-clojure-repl.html</guid>
  <pubDate>Thu, 04 Oct 2018 11:21:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[VM flags from running JVM]]></title>
  <description><![CDATA[
<p>
While I was doing some JVM GC analysis recently, I got curious about the vm flags that `java` command uses by default if you do not specify it when starting your JVM.
Reading up JDK docs, I found <b>jcmd</b> is exactly what you need:
</p>
<div class="org-src-container">
<pre class="src src-shell">jcmd
</pre>
</div>
<p>
That will list all jvm instances running on your system beginning with
its pids, which you can pass into <b>jcmd</b> with options to print VM flags like this:
</p>
<div class="org-src-container">
<pre class="src src-shell">jcmd &lt;pid&gt; VM.flags
</pre>
</div>
<p>
There are many options you can use other than `VM.flags`, which you can get a full list by:
</p>
<div class="org-src-container">
<pre class="src src-shell">jcmd &lt;pid&gt; help
</pre>
</div>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-jvm.html">jvm</a> </div>]]></description>
  <category><![CDATA[jvm]]></category>
  <link>https://www.birkey.co/2018-10-03-vm-flags-from-running-jvm.html</link>
  <guid>https://www.birkey.co/2018-10-03-vm-flags-from-running-jvm.html</guid>
  <pubDate>Wed, 03 Oct 2018 12:03:00 -0700</pubDate>
</item>
<item>
  <title><![CDATA[Blogging Made Simple]]></title>
  <description><![CDATA[
<p>
After taking some time off from work to focus on projects that I like
to take on, I set out to find a simple way to use git and emacs workflow to
start blogging again. Among plethora of options on the web, I came
across this project - <a href="https://github.com/bastibe/org-static-blog">Org Static Blog</a> - that I resonated with. It took
me no time to set it up and start blogging. Below is my setup:
</p>
<div class="org-src-container">
<pre class="src src-emacs-lisp">(use-package org-static-blog
  :straight t
  :config
  ;; -----------------------------------------------------------------------------
  ;; Set up blogging in Emacs
  ;; -----------------------------------------------------------------------------

  (setq org-static-blog-publish-title "BirkeyCo")
  (setq org-static-blog-publish-url "https://www.birkey.co/")
  (setq org-static-blog-publish-directory "~/github/oneness.github.io/")
  (setq org-static-blog-posts-directory "~/github/oneness.github.io/posts/")
  (setq org-static-blog-drafts-directory "~/github/oneness.github.io/drafts/")
  ;;(setq org-static-blog-enable-tags t)
  (setq org-export-with-toc nil)
  (setq org-export-with-section-numbers nil)

  (setq org-static-blog-page-header
	"&lt;meta name=\"author\" content=\"Kasim Tuman\"&gt;
&lt;meta name=\"referrer\" content=\"no-referrer\"&gt;
&lt;link href= \"static/style.css\" rel=\"stylesheet\" type=\"text/css\" /&gt;
&lt;link rel=\"icon\" href=\"static/favicon.ico\"&gt;
&lt;link rel=\"apple-touch-icon-precomposed\" href=\"static/birkey_logo.png\"&gt;
&lt;link rel=\"msapplication-TitleImage\" href=\"static/birkey_logo.png\"&gt;
&lt;link rel=\"msapplication-TitleColor\" href=\"#0141ff\"&gt;
&lt;script src=\"static/katex.min.js\"&gt;&lt;/script&gt;
&lt;script src=\"static/auto-render.min.js\"&gt;&lt;/script&gt;
&lt;link rel=\"stylesheet\" href=\"static/katex.min.css\"&gt;
&lt;script&gt;document.addEventListener(\"DOMContentLoaded\", function() { renderMathInElement(document.body); });&lt;/script&gt;
&lt;meta http-equiv=\"content-type\" content=\"application/xhtml+xml; charset=UTF-8\"&gt;
&lt;meta name=\"viewport\" content=\"initial-scale=1,width=device-width,minimum-scale=1\"&gt;")

  (setq org-static-blog-page-preamble
	"&lt;div class=\"header\"&gt;
  &lt;a href=\"https://birkey.co\"&gt;Code, Data and Network&lt;/a&gt;
  &lt;div class=\"sitelinks\"&gt;
    &lt;a href=\"https://twitter.com/KasimTuman\"&gt;Twitter&lt;/a&gt; | &lt;a href=\"https://github.com/oneness\"&gt;Github&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;")

  (setq org-static-blog-page-postamble
	"&lt;div id=\"archive\"&gt;
  &lt;a href=\"https://www.birkey.co/archive.html\"&gt;Other posts&lt;/a&gt;
&lt;/div&gt;
&lt;center&gt;&lt;a rel=\"license\" href=\"https://creativecommons.org/licenses/by-sa/3.0/\"&gt;&lt;img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/3.0/88x31.png\" /&gt;&lt;/a&gt;&lt;br /&gt;&lt;span xmlns:dct=\"https://purl.org/dc/terms/\" href=\"https://purl.org/dc/dcmitype/Text\" property=\"dct:title\" rel=\"dct:type\"&gt;birkey.co&lt;/span&gt; by &lt;a xmlns:cc=\"https://creativecommons.org/ns#\" href=\"https://www.birkey.co\" property=\"cc:attributionName\" rel=\"cc:attributionURL\"&gt;Kasim Tuman&lt;/a&gt; is licensed under a &lt;a rel=\"license\" href=\"https://creativecommons.org/licenses/by-sa/3.0/\"&gt;Creative Commons Attribution-ShareAlike 3.0 Unported License&lt;/a&gt;.&lt;/center&gt;")

  ;; This slows down org-publish to a crawl, and it is not needed since
  ;; I use magit anyway.
  (remove-hook 'find-file-hooks 'vc-find-file-hook))
</pre>
</div>
<div class="taglist"><a href="https://www.birkey.co/tags.html">Tags</a>: <a href="https://www.birkey.co/tag-emacs.html">emacs</a> <a href="https://www.birkey.co/tag-blogging.html">blogging</a> </div>]]></description>
  <category><![CDATA[emacs]]></category>
  <category><![CDATA[blogging]]></category>
  <link>https://www.birkey.co/2018-9-20-blogging-simpler.html</link>
  <guid>https://www.birkey.co/2018-9-20-blogging-simpler.html</guid>
  <pubDate>Thu, 20 Sep 2018 00:00:00 -0700</pubDate>
</item>
</channel>
</rss>
